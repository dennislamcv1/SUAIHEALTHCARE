{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a96f44a2-b3bf-4530-9a9d-53e2e78a1e3f",
   "metadata": {
    "id": "97d56c15-5561-4d89-89eb-d3e4facbc8c9"
   },
   "source": [
    "# K-means Clustering for Patient Segmentation\n",
    "\n",
    "\n",
    "Time estimate: **30** minutes\n",
    "\n",
    "## Objectives\n",
    "\n",
    "After completing this lab, you will be able to:\n",
    "\n",
    " - Explain the purpose of clustering in population health research\n",
    " - Prepare and preprocess patient datasets for clustering analysis\n",
    " - Apply K-means clustering to segment patients into distinct subgroups\n",
    " - Determine the optimal number of clusters using the elbow method\n",
    " - Analyze and interpret cluster characteristics to identify patterns in patient demographics and health variables\n",
    " - Visualize clusters using dimensionality reduction techniques like PCA\n",
    " - Develop practical skills in Python for performing clustering on anonymized patient data\n",
    "\n",
    "## What you will do in this lab\n",
    "\n",
    "In this lab, you will work with a simulated patient dataset containing demographic and health information. You will apply K-means clustering, a popular unsupervised machine learning technique, to identify distinct patient subgroups based on their characteristics.\n",
    "\n",
    "You will:\n",
    "\n",
    "- Load and explore an anonymized patient dataset with multiple health features\n",
    "- Preprocess the data by handling missing values, encoding categorical variables, and standardizing numeric features\n",
    "- Apply K-means clustering to segment patients into three distinct groups\n",
    "- Analyze the characteristics of each cluster to understand patient patterns\n",
    "- Visualize the clusters using Principal Component Analysis (PCA) for 2D representation\n",
    "- Practice clustering on an additional brain stroke risk dataset\n",
    "\n",
    "## Overview\n",
    "\n",
    "Clustering is an unsupervised machine learning technique that groups similar data points together based on their characteristics. In healthcare, clustering helps identify patient subgroups with similar health profiles, enabling personalized treatment strategies and targeted interventions.\n",
    "\n",
    "K-means clustering is one of the most widely used clustering algorithms. It works by partitioning data into K distinct clusters, where each data point belongs to the cluster with the nearest centroid (center point). The algorithm iteratively assigns points to clusters and updates centroids until convergence.\n",
    "\n",
    "In this lab, you will work with a patient dataset containing demographic information, vital signs, laboratory values, and health history. The goal is to discover natural groupings in the data that may represent different patient risk profiles or health conditions. Understanding these patterns can help healthcare providers develop targeted prevention and treatment strategies.\n",
    "\n",
    "Before applying K-means, proper data preprocessing is essential. This includes handling missing values, encoding categorical variables into numeric form, and standardizing features to ensure all variables contribute equally to the clustering process. You will learn these critical preprocessing steps and understand why they are necessary for effective clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf56d93-a5d9-4e42-810b-10f4c46a628e",
   "metadata": {
    "id": "97d56c15-5561-4d89-89eb-d3e4facbc8c9"
   },
   "source": [
    "## About the dataset\n",
    "\n",
    "In this lab, you will work with a simulated patient dataset designed for population health research. The dataset contains anonymized health records with demographic information, vital signs, laboratory values, and medical history.\n",
    "\n",
    "### Dataset overview\n",
    "\n",
    "The patient dataset consists of 6,000 anonymized patient records with 16 features covering various aspects of patient health. This dataset combines cardiovascular, metabolic, and lifestyle factors to create a comprehensive health profile for each patient. The data has been specifically designed for clustering analysis to identify distinct patient subgroups that may benefit from targeted healthcare interventions.\n",
    "\n",
    "The dataset includes both numeric features (such as age, blood pressure, and cholesterol levels) and categorical features (such as gender, residence type, and smoking status). Some features contain missing values, which is common in real-world healthcare datasets and requires proper handling during preprocessing.\n",
    "\n",
    "### Column descriptions\n",
    "\n",
    "1. **age** - Patient's age in years (numeric, range: 18-90)\n",
    "2. **gender** - Patient's gender (categorical: 0 = Female, 1 = Male)\n",
    "3. **chest_pain_type** - Type of chest pain experienced (categorical: 1 = Typical Angina, 2 = Atypical Angina, 3 = Non-Anginal Pain, 4 = Asymptomatic)\n",
    "4. **blood_pressure** - Resting blood pressure in mm Hg (numeric, range: 0-300)\n",
    "5. **cholesterol** - Serum cholesterol level in mg/dl (numeric, range: 120-300)\n",
    "6. **max_heart_rate** - Maximum heart rate achieved during exercise (numeric, range: 70-220)\n",
    "7. **exercise_angina** - Angina experienced during exercise (categorical: 0 = No, 1 = Yes)\n",
    "8. **plasma_glucose** - Plasma glucose concentration in mg/dl (numeric, range: 70-250)\n",
    "9. **skin_thickness** - Skinfold thickness in mm (numeric, range: 20-100)\n",
    "10. **insulin** - Serum insulin level in µU/ml (numeric, range: 80-180)\n",
    "11. **bmi** - Body Mass Index calculated as weight/height² (numeric, range: 10-50)\n",
    "12. **diabetes_pedigree** - Diabetes pedigree function representing family history risk (numeric, range: 0.1-2.5)\n",
    "13. **hypertension** - History of hypertension (categorical: 0 = No, 1 = Yes)\n",
    "14. **heart_disease** - History of heart disease (categorical: 0 = No, 1 = Yes)\n",
    "15. **residence_type** - Type of area where the patient lives (categorical: Urban, Rural)\n",
    "16. **smoking_status** - Patient's smoking status (categorical: Smoker, Non-Smoker, Unknown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be7a9f8-e9c4-4c3d-a955-364d863cdf47",
   "metadata": {
    "id": "9be7a9f8-e9c4-4c3d-a955-364d863cdf47"
   },
   "source": [
    "## Setup\n",
    "\n",
    "### Installing required libraries\n",
    "\n",
    "The following libraries are required to run this lab. If you are running this notebook in a local environment, you may need to install these libraries using pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lxa62hhgam",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the libraries required for this lab\n",
    "!pip install pandas numpy matplotlib seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qbvll5lczc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: suppress warnings for cleaner output\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d9sj49rwc",
   "metadata": {},
   "source": [
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca50e1ef-244a-4b0c-be92-e28c6df3a363",
   "metadata": {
    "executionInfo": {
     "elapsed": 5348,
     "status": "ok",
     "timestamp": 1759753604815,
     "user": {
      "displayName": "Ramesh S",
      "userId": "12785615939781378195"
     },
     "user_tz": -330
    },
    "id": "ca50e1ef-244a-4b0c-be92-e28c6df3a363"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries for data manipulation and clustering\n",
    "import pandas as pd      # For loading, inspecting, and manipulating tabular data (DataFrames)\n",
    "import numpy as np       # For numerical operations, arrays, and mathematical functions\n",
    "import matplotlib.pyplot as plt   # For creating static plots, charts, and visualizations\n",
    "import seaborn as sns    # For advanced statistical visualizations (heatmaps, scatterplots, pairplots)\n",
    "\n",
    "# Import machine learning modules for clustering\n",
    "from sklearn.cluster import KMeans        # K-means clustering algorithm for segmenting patients into clusters\n",
    "from sklearn.preprocessing import StandardScaler  # For standardizing features (mean=0, variance=1) before clustering\n",
    "from sklearn.decomposition import PCA             # Principal Component Analysis for dimensionality reduction and 2D visualization\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(\"Ready to begin K-means clustering analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b512025-26da-4e0b-a30d-9c42ba365227",
   "metadata": {
    "id": "5b512025-26da-4e0b-a30d-9c42ba365227"
   },
   "source": [
    "## Step 1: Load the patient dataset\n",
    "\n",
    "The first step in any data analysis project is to load the dataset into a pandas DataFrame. A DataFrame is a tabular data structure that allows you to easily manipulate and analyze data.\n",
    "\n",
    "In this step, you will load the patient_dataset.csv file and verify that it has been loaded successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cdd89a-5e50-459b-a6f5-14365735b97a",
   "metadata": {
    "executionInfo": {
     "elapsed": 99,
     "status": "ok",
     "timestamp": 1759753684749,
     "user": {
      "displayName": "Ramesh S",
      "userId": "12785615939781378195"
     },
     "user_tz": -330
    },
    "id": "9ec133f3-b818-4139-8d24-bf1789c6e3bb"
   },
   "outputs": [],
   "source": [
    "# Specify the path to the patient dataset CSV file\n",
    "file_path = \"https://advanced-machine-learning-for-medical-data-8e1579.gitlab.io/labs/lab4/patient_dataset.csv\"\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display success message\n",
    "print(\"File loaded successfully!\")\n",
    "\n",
    "# Display the first few rows to preview the data\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a667aba3-975b-4f3f-ac69-4d554b78cb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the column names in the dataset\n",
    "print(\"\\nColumn names:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Display dataset dimensions (rows and columns)\n",
    "print(f\"\\nDataset shape: {df.shape[0]} rows, {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b289c2-aeb1-4bca-8d55-5fabbb7e1694",
   "metadata": {
    "id": "f6b289c2-aeb1-4bca-8d55-5fabbb7e1694"
   },
   "source": [
    "## Step 2: Explore the dataset\n",
    "\n",
    "Before applying any machine learning algorithm, it is essential to understand the structure and characteristics of your data. In this step, you will examine:\n",
    "\n",
    "- Basic dataset information (data types, non-null counts)\n",
    "- Summary statistics for numeric features\n",
    "- Missing values in each column\n",
    "- Unique values in categorical features\n",
    "\n",
    "This exploration helps identify data quality issues and informs preprocessing decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a27a7e7-ef6a-4519-baac-073c653abe24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1759753687232,
     "user": {
      "displayName": "Ramesh S",
      "userId": "12785615939781378195"
     },
     "user_tz": -330
    },
    "id": "0a27a7e7-ef6a-4519-baac-073c653abe24",
    "outputId": "cde84e0a-2f73-462f-8e53-d21d81019466"
   },
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "# This shows data types, number of non-null values, and memory usage\n",
    "print(\"Dataset information (columns, data types, non-null counts):\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a366f9-9524-4dd9-95de-34e0bc193565",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1759753690110,
     "user": {
      "displayName": "Ramesh S",
      "userId": "12785615939781378195"
     },
     "user_tz": -330
    },
    "id": "41a366f9-9524-4dd9-95de-34e0bc193565",
    "outputId": "9815af77-8b49-4a87-eb0f-cf687f05e193"
   },
   "outputs": [],
   "source": [
    "# Check for missing values in each column\n",
    "# Missing values must be handled before clustering\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1edcc3e-fb70-4588-b898-28f1f8d620aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1759753692363,
     "user": {
      "displayName": "Ramesh S",
      "userId": "12785615939781378195"
     },
     "user_tz": -330
    },
    "id": "b1edcc3e-fb70-4588-b898-28f1f8d620aa",
    "outputId": "287257f6-4979-42a1-cf20-1a56cd8d1a17"
   },
   "outputs": [],
   "source": [
    "# Display summary statistics for numeric features\n",
    "# This includes count, mean, standard deviation, min, max, and quartiles\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "print(\"\\nSummary statistics for numeric features:\")\n",
    "df[numeric_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e0b8fb-2735-418d-9237-45ad50d864e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1759753695568,
     "user": {
      "displayName": "Ramesh S",
      "userId": "12785615939781378195"
     },
     "user_tz": -330
    },
    "id": "40e0b8fb-2735-418d-9237-45ad50d864e4",
    "outputId": "c32f035a-eaea-416e-f4cf-71e22558be13"
   },
   "outputs": [],
   "source": [
    "# Display unique values for categorical features\n",
    "# This helps understand the categories you need to encode\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "print(\"\\nUnique values for categorical features:\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"{col}: {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecb6d65-c738-4cbb-97a3-8e6ce26c8633",
   "metadata": {
    "id": "9ecb6d65-c738-4cbb-97a3-8e6ce26c8633"
   },
   "source": [
    "## Step 3: Preprocess the data\n",
    "\n",
    "Data preprocessing is a critical step before applying K-means clustering. Raw data often contains missing values, categorical variables, and features with different scales, which can negatively impact clustering results.\n",
    "\n",
    "In this step, you will perform the following preprocessing tasks:\n",
    "\n",
    "1. **Separate numeric and categorical columns** - Different data types require different preprocessing approaches\n",
    "2. **Fill missing values** - K-means cannot handle missing data, so you must impute (fill) missing values\n",
    "3. **Encode categorical variables** - Convert categorical text into numeric form using one-hot encoding\n",
    "4. **Standardize numeric features** - Scale all features to have mean=0 and standard deviation=1\n",
    "\n",
    "### Why preprocessing matters\n",
    "\n",
    "**Handling missing values:** Machine learning algorithms cannot process missing data. You use mean imputation for numeric features and mode imputation for categorical features.\n",
    "\n",
    "**Encoding categorical variables:** K-means uses Euclidean distance, which requires all features to be numeric. One-hot encoding converts categories such as \"Urban\" and \"Rural\" into binary columns.\n",
    "\n",
    "**Standardization:** Features with larger ranges (e.g., cholesterol: 120-300) would dominate distance calculations over smaller ranges (e.g., gender: 0-1). Standardization ensures all features contribute equally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fa842c-e721-42ed-9d6d-723f8601542a",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1759753700751,
     "user": {
      "displayName": "Ramesh S",
      "userId": "12785615939781378195"
     },
     "user_tz": -330
    },
    "id": "49fa842c-e721-42ed-9d6d-723f8601542a"
   },
   "outputs": [],
   "source": [
    "# Step 3.1: Separate numeric and categorical columns\n",
    "# Numeric columns will be scaled, categorical columns will be encoded\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "print(f\"Numeric columns ({len(numeric_cols)}): {list(numeric_cols)}\")\n",
    "print(f\"\\nCategorical columns ({len(categorical_cols)}): {list(categorical_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b00770-47b3-4408-91ab-31ad5eb36673",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1759753704841,
     "user": {
      "displayName": "Ramesh S",
      "userId": "12785615939781378195"
     },
     "user_tz": -330
    },
    "id": "f4b00770-47b3-4408-91ab-31ad5eb36673"
   },
   "outputs": [],
   "source": [
    "# Step 3.2: Fill missing values\n",
    "# For numeric columns: fill with the mean (average) value\n",
    "# For categorical columns: fill with the mode (most frequent) value\n",
    "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
    "df[categorical_cols] = df[categorical_cols].fillna(df[categorical_cols].mode().iloc[0])\n",
    "\n",
    "print(\"Missing values filled successfully!\")\n",
    "print(\"\\nVerifying - Missing values remaining:\")\n",
    "print(df.isnull().sum().sum())  # Should be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e883d0c-2096-49cf-86d0-297f3ceffb1e",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1759753709351,
     "user": {
      "displayName": "Ramesh S",
      "userId": "12785615939781378195"
     },
     "user_tz": -330
    },
    "id": "4e883d0c-2096-49cf-86d0-297f3ceffb1e"
   },
   "outputs": [],
   "source": [
    "# Step 3.3: Encode categorical variables using one-hot encoding\n",
    "# This converts categorical features into binary columns (0 or 1)\n",
    "# drop_first=True prevents multicollinearity by dropping one category per feature\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "print(\"Categorical variables encoded successfully!\")\n",
    "print(f\"\\nDataset shape after encoding: {df_encoded.shape[0]} rows, {df_encoded.shape[1]} columns\")\n",
    "print(\"\\nNew encoded columns:\")\n",
    "print([col for col in df_encoded.columns if col not in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca4fce9-299e-4faa-9f00-4ad6425e2504",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1759753713047,
     "user": {
      "displayName": "Ramesh S",
      "userId": "12785615939781378195"
     },
     "user_tz": -330
    },
    "id": "eca4fce9-299e-4faa-9f00-4ad6425e2504",
    "outputId": "9186b476-f8fc-4904-d702-eb39a840beb4"
   },
   "outputs": [],
   "source": [
    "# Step 3.4: Standardize numeric features using StandardScaler\n",
    "# This transforms each feature to have mean=0 and standard deviation=1\n",
    "# Standardization ensures all features contribute equally to distance calculations\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_encoded)\n",
    "\n",
    "print(\"Preprocessing complete!\")\n",
    "print(\"All features have been standardized and are ready for K-means clustering.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085ea336-2823-43a3-9036-8c28303c4254",
   "metadata": {
    "id": "085ea336-2823-43a3-9036-8c28303c4254"
   },
   "source": [
    "## Step 4: Apply K-means clustering\n",
    "\n",
    "Now that the data is preprocessed, you can apply the K-means clustering algorithm. K-means groups similar data points into K clusters based on Euclidean distance.\n",
    "\n",
    "### How K-means works\n",
    "\n",
    "1. **Initialize K centroids** randomly (or using smart initialization like k-means++)\n",
    "2. **Assign each point** to the nearest centroid\n",
    "3. **Update centroids** by calculating the mean of all points in each cluster\n",
    "4. **Repeat steps 2-3** until centroids stop moving (convergence)\n",
    "\n",
    "### Key parameters\n",
    "\n",
    "- **n_clusters:** The number of clusters (K). In this lab, you use K=3 to identify three patient subgroups\n",
    "- **init='k-means++':** Smart initialization method that improves convergence\n",
    "- **max_iter:** Maximum number of iterations (300 is typically sufficient)\n",
    "- **n_init:** Number of times the algorithm runs with different initial centroids (10 is default)\n",
    "- **random_state:** Ensures reproducibility by fixing the random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_DrvWF55bP2B",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1759753715581,
     "user": {
      "displayName": "Ramesh S",
      "userId": "12785615939781378195"
     },
     "user_tz": -330
    },
    "id": "_DrvWF55bP2B"
   },
   "outputs": [],
   "source": [
    "# Convert the scaled NumPy array back to a DataFrame\n",
    "# This makes it easier to work with and add the cluster labels\n",
    "df_scaled = pd.DataFrame(df_scaled, columns=df_encoded.columns)\n",
    "\n",
    "print(\"Data converted back to DataFrame format.\")\n",
    "print(f\"Shape: {df_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6d5aae-544a-4f19-87ed-77d9cf47783b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 165,
     "status": "ok",
     "timestamp": 1759753717335,
     "user": {
      "displayName": "Ramesh S",
      "userId": "12785615939781378195"
     },
     "user_tz": -330
    },
    "id": "1c6d5aae-544a-4f19-87ed-77d9cf47783b",
    "outputId": "13b8f495-9fd9-4312-a349-bfcd875e0267"
   },
   "outputs": [],
   "source": [
    "# Apply K-means clustering with K=3 clusters\n",
    "optimal_k = 3\n",
    "\n",
    "# Initialize the K-means model\n",
    "kmeans = KMeans(\n",
    "    n_clusters=optimal_k,      # Number of clusters\n",
    "    init='k-means++',           # Smart initialization\n",
    "    max_iter=300,               # Maximum iterations\n",
    "    n_init=10,                  # Number of runs with different initializations\n",
    "    random_state=42             # For reproducibility\n",
    ")\n",
    "\n",
    "# Fit the model and predict cluster labels for each patient\n",
    "df_scaled['Cluster'] = kmeans.fit_predict(df_scaled)\n",
    "\n",
    "print(\"K-means clustering complete!\")\n",
    "print(f\"\\nPatients have been segmented into {optimal_k} clusters.\")\n",
    "print(f\"\\nCluster distribution:\")\n",
    "print(df_scaled['Cluster'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669043c3-056d-4760-8bb8-2c39d40130ea",
   "metadata": {
    "id": "669043c3-056d-4760-8bb8-2c39d40130ea"
   },
   "source": [
    "## Step 5: Analyze cluster characteristics\n",
    "\n",
    "After clustering, it's important to understand what differentiates each cluster. By examining the mean values of features in each cluster, you can identify distinct patient subgroups and their characteristics.\n",
    "\n",
    "This analysis helps answer questions like:\n",
    "- Which cluster has older patients?\n",
    "- Which cluster has higher cholesterol levels?\n",
    "- Which cluster is associated with more health risk factors?\n",
    "\n",
    "These insights can inform targeted healthcare interventions and personalized treatment strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e45abc-c15f-48cc-a9d2-37d52b58fd01",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1759753719497,
     "user": {
      "displayName": "Ramesh S",
      "userId": "12785615939781378195"
     },
     "user_tz": -330
    },
    "id": "d6e45abc-c15f-48cc-a9d2-37d52b58fd01",
    "outputId": "e36dd018-dc5d-45a8-9066-f757981957df"
   },
   "outputs": [],
   "source": [
    "# Calculate the mean value of each feature for each cluster\n",
    "# This shows the average characteristics of patients in each cluster\n",
    "print(\"Cluster summary (mean values):\")\n",
    "cluster_summary = df_scaled.groupby('Cluster').mean()\n",
    "\n",
    "\n",
    "# Note: Values are standardized (mean=0, std=1)\n",
    "# Positive values indicate above-average for that feature\n",
    "# Negative values indicate below-average for that feature\n",
    "cluster_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23b5e91-39a0-4ed3-acbd-fef34a674378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy the Cluster information to the original DataFrame\n",
    "df['Cluster'] = df_scaled['Cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee49a0d-8f0c-4aac-a9f2-76b85569d9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster summary based on the original data frame\n",
    "df.groupby('Cluster').mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1664de8-942f-4324-b6d2-2179ede71995",
   "metadata": {
    "id": "a1664de8-942f-4324-b6d2-2179ede71995"
   },
   "source": [
    "## Step 6: Visualize clusters using PCA\n",
    "\n",
    "With many features (16+ after encoding), it's impossible to visualize clusters in high-dimensional space. Principal Component Analysis (PCA) solves this problem by reducing dimensionality while preserving the most important patterns in the data.\n",
    "\n",
    "### What is PCA?\n",
    "\n",
    "PCA transforms high-dimensional data into a lower-dimensional representation by finding the directions (principal components) with the most variance. The first two principal components (PC1 and PC2) capture the most significant patterns, allowing you to create a 2D visualization.\n",
    "\n",
    "### Why use PCA for visualization?\n",
    "\n",
    "- **Dimensionality reduction:** Converts 16+ dimensions to 2 dimensions\n",
    "- **Pattern preservation:** Retains the most important relationships between patients\n",
    "- **Visual interpretation:** Makes it easy to see cluster separation and overlap\n",
    "\n",
    "In the visualization, each point represents a patient, and colors represent cluster assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ee7e35-7508-4dc1-a5ca-1e934964b42f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 1698,
     "status": "ok",
     "timestamp": 1759753724932,
     "user": {
      "displayName": "Ramesh S",
      "userId": "12785615939781378195"
     },
     "user_tz": -330
    },
    "id": "d8ee7e35-7508-4dc1-a5ca-1e934964b42f",
    "outputId": "ccf21326-9baf-4250-822f-eeb3314f2843"
   },
   "outputs": [],
   "source": [
    "# Apply PCA to reduce dimensions from 16+ to 2 for visualization\n",
    "pca = PCA(n_components=2)  # Keep only the first 2 principal components\n",
    "\n",
    "# Transform the scaled data\n",
    "principal_components = pca.fit_transform(df_scaled.drop('Cluster', axis=1))\n",
    "\n",
    "# Create a DataFrame with the 2 principal components\n",
    "df_pca = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n",
    "df_pca['Cluster'] = df_scaled['Cluster'].values\n",
    "\n",
    "# Create a scatter plot showing clusters in 2D space\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(\n",
    "    x='PC1', \n",
    "    y='PC2', \n",
    "    hue='Cluster',  # Color points by cluster\n",
    "    data=df_pca, \n",
    "    palette='viridis',  # Color scheme\n",
    "    s=50,  # Point size\n",
    "    alpha=0.7  # Transparency\n",
    ")\n",
    "plt.title(\"PCA Visualization of K-means Clusters\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Principal Component 1 (PC1)\", fontsize=12)\n",
    "plt.ylabel(\"Principal Component 2 (PC2)\", fontsize=12)\n",
    "plt.legend(title='Cluster', fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the variance explained by the first 2 components\n",
    "print(f\"\\nVariance explained by PC1: {pca.explained_variance_ratio_[0]:.2%}\")\n",
    "print(f\"Variance explained by PC2: {pca.explained_variance_ratio_[1]:.2%}\")\n",
    "print(f\"Total variance explained: {sum(pca.explained_variance_ratio_):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a72e2e1-b67a-4386-a03c-bcc0e38b46e0",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "Now it's your turn to apply what you've learned! In these exercises, you will work with a different dataset called **brain_stroke_clusters.csv** (https://advanced-machine-learning-for-medical-data-8e1579.gitlab.io/labs/lab4/brain_stroke_clusters.csv), which contains patient data related to stroke risk factors.\n",
    "\n",
    "Your goal is to perform K-means clustering on this dataset to identify patient subgroups with different stroke risk profiles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa491fd-e86a-4b73-b6cd-95a2e7977f3e",
   "metadata": {},
   "source": [
    "## Exercise 1: Import the required libraries\n",
    "\n",
    "Import the necessary libraries for this exercise. You will need pandas, scikit-learn modules, matplotlib, and seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c095ae-c8a2-4008-8b90-8547aa481726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uuael7np9zc",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for a hint</summary>\n",
    "    \n",
    "You need to import: pandas, StandardScaler and KMeans from sklearn, matplotlib.pyplot, and seaborn.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3vvb6pnfsl",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3156089f-86db-4886-afc7-4bfb693aa4d9",
   "metadata": {},
   "source": [
    "## Exercise 2: Load the dataset\n",
    "\n",
    "Load the brain_stroke_clusters.csv file into a pandas DataFrame and display a success message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0ea9ce-a7a1-4fce-b1e1-39a6650e3207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf82944-8dc7-4312-9014-24d1832eefff",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for a hint</summary>\n",
    "    \n",
    "Use pd.read_csv() to load the CSV file. Refer to Step 1 of this lab.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936ff99b-6953-41c4-9990-e8731447b3bd",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "# Specify the path to the brain stroke dataset\n",
    "file_path = \"https://advanced-machine-learning-for-medical-data-8e1579.gitlab.io/labs/lab4/brain_stroke_clusters.csv\"\n",
    "\n",
    "# Load CSV into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display success message\n",
    "print(\"File loaded successfully!\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb78e9c-d788-4334-8c30-c2173cc4f1c5",
   "metadata": {},
   "source": [
    "## Exercise 3: Explore the dataset\n",
    "\n",
    "Display the number of rows, column names, and the first 5 rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c2c2b3-376c-4904-be63-80daa6f447c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876f8771-6e04-4a1e-b43b-2927d0c5fd04",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for a hint</summary>\n",
    "    \n",
    "Use df.shape[0] for row count, df.columns.tolist() for column names, and df.head() to display the first 5 rows.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5c5275-fd5f-4ced-9a3d-d2849d5c6a94",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "print(\"Number of rows:\", df.shape[0])\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4124167d-a795-4485-99cf-35167702f496",
   "metadata": {},
   "source": [
    "## Exercise 4: Check for categorical features\n",
    "\n",
    "Check if there are any categorical features in the dataset by displaying unique values for categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb483e1-2485-487d-a23b-5ef9c9b90e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090ee8e8-1806-488f-8519-2212d931a8a8",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for a hint</summary>\n",
    "    \n",
    "Use df.select_dtypes(include=['object', 'category']) to find categorical columns. Refer to Step 2 of this lab.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138a7c2a-1ac2-431b-9923-e2a0e540e2c5",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "# Check unique values for categorical features\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "print(\"Unique values for categorical features:\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"{col}: {df[col].unique()}\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7bbb17-562b-4d08-a15b-7e69cd849524",
   "metadata": {},
   "source": [
    "## Exercise 5: Prepare and standardize the data\n",
    "\n",
    "Select the features for clustering (age, avg_glucose_level, bmi) and standardize them using StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa13e8aa-3810-4c70-9188-463eaa029b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530c22b0-b03f-4af2-a8a9-e25268b32d5d",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for a hint</summary>\n",
    "    \n",
    "First, select the three numeric columns into a variable X. Then use StandardScaler().fit_transform() to standardize. Refer to Step 3 of this lab.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40630634-11bb-49fd-85e5-01483863af83",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "# Select features for clustering\n",
    "X = df[['age', 'avg_glucose_level', 'bmi']]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"Data standardized successfully!\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8f077c-bed2-49e5-a2ee-6e09ec311c37",
   "metadata": {},
   "source": [
    "## Exercise 6: Apply K-means with k=2\n",
    "\n",
    "Apply K-means clustering with 2 clusters and add the cluster labels to the original DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963c3e1d-ebb0-4160-bc62-4e40e89995bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce9ab66-f5c5-49af-b5fc-77bd5eb8f21f",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for a hint</summary>\n",
    "    \n",
    "Create a KMeans object with n_clusters=2 and random_state=42. Use fit_predict() on the scaled data and store the results in a new column called 'cluster'. Refer to Step 4 of this lab.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31c8db-138d-497e-ab21-69c784f28261",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "# Apply K-means with k=2\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "print(\"K-means clustering complete!\")\n",
    "print(\"\\nCluster distribution:\")\n",
    "print(df['cluster'].value_counts())\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4cc108-5cc2-4ac6-9ee8-5a7999e96d6c",
   "metadata": {},
   "source": [
    "## Exercise 7: Visualize the clusters\n",
    "\n",
    "Create a scatter plot showing the clusters with avg_glucose_level on the x-axis and bmi on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260e4320-3526-40e2-8b61-46e6f6922620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f94ed96-e215-41ac-95f0-f0b4cb824401",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for a hint</summary>\n",
    "    \n",
    "Use sns.scatterplot() with x='avg_glucose_level', y='bmi', and hue='cluster'. Refer to Step 6 of this lab.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ee5038-2cda-45ce-b0d0-bf9edf512d04",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "# Visualize clusters\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(\n",
    "    x='avg_glucose_level',\n",
    "    y='bmi',\n",
    "    hue='cluster',\n",
    "    data=df,\n",
    "    palette='Set1',\n",
    "    s=80\n",
    ")\n",
    "plt.title('K-Means Clustering of Stroke Risk Groups')\n",
    "plt.xlabel('Average Glucose Level')\n",
    "plt.ylabel('BMI')\n",
    "plt.legend(title='Cluster')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0lt84vpxf1a",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "You have successfully completed this lab on K-means clustering for patient segmentation! You learned how to preprocess healthcare data, apply K-means clustering to identify distinct patient subgroups, analyze cluster characteristics, and visualize results using PCA. These skills are valuable for population health research and can help healthcare providers develop targeted interventions and personalized treatment strategies.\n",
    "\n",
    "## Authors\n",
    "\n",
    "Ramesh Sannareddy\n",
    "\n",
    "Copyright © 2025 SkillUp. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
