{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17e4e5b3-0eac-4864-a525-4a5d05dade66",
   "metadata": {
    "id": "17e4e5b3-0eac-4864-a525-4a5d05dade66"
   },
   "source": [
    "# Training a Neural Network for Disease Detection in Chest X-rays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287dccad-d667-4d02-971a-866d038e3570",
   "metadata": {
    "id": "287dccad-d667-4d02-971a-866d038e3570"
   },
   "source": [
    "Time estimate: **30** minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04653a2c-4867-4faa-9302-b832d968ea93",
   "metadata": {
    "id": "04653a2c-4867-4faa-9302-b832d968ea93"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this lab, you will be able to:\n",
    "\n",
    " - Build and train a fully connected neural network using the ChestMNIST dataset from MedMNIST\n",
    " - Predict multiple pathologies from chest X-ray images through multi-label classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb335e6-b02d-4db7-b093-dc0e88aa0f59",
   "metadata": {
    "id": "3cb335e6-b02d-4db7-b093-dc0e88aa0f59"
   },
   "source": [
    "## What you will do in this lab\n",
    "\n",
    "In this lab, you will work with the ChestMNIST dataset from MedMNIST to develop and test a neural network model for multi-label medical image classification.\n",
    "\n",
    "You will:\n",
    "- Load and preprocess medical imaging data using MedMNIST\n",
    "- Design a dense neural network for multi-label classification\n",
    "- Handle medical image data with multiple simultaneous conditions\n",
    "- Train a model with appropriate hyperparameters for medical imaging\n",
    "- Evaluate multi-label classification performance using clinically relevant metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a32e167-786c-4f66-ba96-d68af3d4eb23",
   "metadata": {
    "id": "0a32e167-786c-4f66-ba96-d68af3d4eb23"
   },
   "source": [
    "## Overview\n",
    "\n",
    "Multi-label classification in medical imaging presents unique challenges compared to traditional single-label classification tasks. In real-world clinical scenarios, patients often present with multiple concurrent pathologies visible in a single chest X-ray. This lab introduces you to building neural networks capable of identifying multiple diseases simultaneously from medical images.\n",
    "\n",
    "You will work with the ChestMNIST dataset, a standardized subset of chest X-ray images from the MedMNIST collection. This dataset contains images labeled with multiple thoracic pathologies, making it ideal for learning multi-label classification techniques. Unlike standard classification where each image belongs to one category, multi-label classification requires the model to predict the presence or absence of several conditions independently.\n",
    "\n",
    "Throughout this lab, you will build a fully connected (dense) neural network architecture suitable for processing medical images. You will learn how to properly preprocess medical imaging data, configure appropriate loss functions and evaluation metrics for multi-label scenarios, and interpret model performance in a clinically meaningful way.\n",
    "\n",
    "Understanding these techniques is essential for developing AI systems that can assist radiologists in detecting multiple pathologies and improving diagnostic accuracy in clinical practice.\n",
    "\n",
    "By the end of this lab, you will have hands-on experience with the complete workflow of developing a multi-label medical image classification system, from data loading through model evaluation, preparing you for more advanced deep learning applications in healthcare.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f0a567-c1b2-46ed-8a86-b30206c26471",
   "metadata": {
    "id": "f9f0a567-c1b2-46ed-8a86-b30206c26471"
   },
   "source": [
    "## About the dataset\n",
    "\n",
    "In this lab, you will use the ChestMNIST dataset, which is derived from the NIH Chest X-ray dataset.\n",
    "\n",
    "- **Dataset Size**: 78,468 chest X-ray images (28×28 grayscale)\n",
    "- **Task**: Multi-label binary classification\n",
    "- **Classes**: 14 thoracic disease labels\n",
    "  1. Atelectasis\n",
    "  2. Cardiomegaly\n",
    "  3. Effusion\n",
    "  4. Infiltration\n",
    "  5. Mass\n",
    "  6. Nodule\n",
    "  7. Pneumonia\n",
    "  8. Pneumothorax\n",
    "  9. Consolidation\n",
    "  10. Edema\n",
    "  11. Emphysema\n",
    "  12. Fibrosis\n",
    "  13. Pleural Thickening\n",
    "  14. Hernia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59c245d-c760-42aa-b5bc-0784384906be",
   "metadata": {
    "id": "f59c245d-c760-42aa-b5bc-0784384906be"
   },
   "source": [
    "## Setup\n",
    "\n",
    "### Installation commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36081b73-a0c8-481c-bde7-309e13f1fbd8",
   "metadata": {
    "id": "36081b73-a0c8-481c-bde7-309e13f1fbd8"
   },
   "outputs": [],
   "source": [
    "!pip -q install medmnist tensorflow numpy matplotlib seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ee29db-7d77-40b0-8c98-1302be76a2a9",
   "metadata": {
    "id": "92ee29db-7d77-40b0-8c98-1302be76a2a9"
   },
   "source": [
    "\n",
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bd1941-ff03-485c-a08a-b6d69ce5bdcc",
   "metadata": {
    "id": "07bd1941-ff03-485c-a08a-b6d69ce5bdcc"
   },
   "outputs": [],
   "source": [
    "### Import required Libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix, roc_auc_score, hamming_loss, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ee25ee-4543-47d3-af77-697c5eff3a9a",
   "metadata": {
    "id": "b9ee25ee-4543-47d3-af77-697c5eff3a9a"
   },
   "source": [
    "## Step 1: Load ChestMNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381a8829-efc7-49a4-afca-7dc18354576b",
   "metadata": {
    "id": "381a8829-efc7-49a4-afca-7dc18354576b"
   },
   "outputs": [],
   "source": [
    "import medmnist\n",
    "from medmnist import INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf5dbee-684b-4d45-92e0-a091f5c08b2a",
   "metadata": {
    "id": "3bf5dbee-684b-4d45-92e0-a091f5c08b2a"
   },
   "outputs": [],
   "source": [
    "# Get dataset information\n",
    "data_flag = 'chestmnist'\n",
    "info = INFO[data_flag]\n",
    "print(f\"\\nDataset: {info['python_class']}\")\n",
    "print(f\"Task: {info['task']}\")\n",
    "print(f\"Number of Classes: {info['n_channels']} input channels, {len(info['label'])} labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a083ae7-61d9-4f63-aa45-1a40eb137d31",
   "metadata": {
    "id": "8a083ae7-61d9-4f63-aa45-1a40eb137d31"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "from medmnist import ChestMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c58846-8c63-4883-913b-90ed1af2d094",
   "metadata": {
    "id": "70c58846-8c63-4883-913b-90ed1af2d094"
   },
   "outputs": [],
   "source": [
    "# Load train, validation, and test sets\n",
    "train_dataset = ChestMNIST(split='train', download=True)\n",
    "val_dataset = ChestMNIST(split='val', download=True)\n",
    "test_dataset = ChestMNIST(split='test', download=True)\n",
    "\n",
    "print(f\"\\nTraining samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f2b258-85d5-4866-a2de-c52c921fe952",
   "metadata": {
    "id": "90f2b258-85d5-4866-a2de-c52c921fe952"
   },
   "source": [
    "## Step 2: Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54873743-5bde-4ca0-b7fe-8ae87e3be6b9",
   "metadata": {
    "id": "54873743-5bde-4ca0-b7fe-8ae87e3be6b9"
   },
   "outputs": [],
   "source": [
    "# Get a sample image and labels\n",
    "img, label = train_dataset[0]\n",
    "\n",
    "# Convert PIL Image to NumPy array to access shape\n",
    "img_array = np.array(img)\n",
    "\n",
    "print(f\"Image shape: {img_array.shape}\")  # (28, 28, 1)\n",
    "print(f\"Label shape: {label.shape}\")  # (14,)\n",
    "print(f\"Label values: {label}\")\n",
    "print(f\"Data type: {img_array.dtype}\")\n",
    "print(f\"Pixel value range: [{img_array.min()}, {img_array.max()}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240c7ebb-8fcf-4cd0-9c65-d039793bcfce",
   "metadata": {
    "id": "240c7ebb-8fcf-4cd0-9c65-d039793bcfce"
   },
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
    "disease_names = ['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration',\n",
    "                 'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax', 'Consolidation',\n",
    "                 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']\n",
    "\n",
    "for idx, ax in enumerate(axes.flat):\n",
    "    if idx < len(train_dataset):\n",
    "        img, label = train_dataset[idx]\n",
    "        # Convert PIL Image to NumPy array before displaying\n",
    "        img_array = np.array(img)\n",
    "        ax.imshow(img_array.squeeze(), cmap='gray')\n",
    "\n",
    "        # Show which diseases are present\n",
    "        diseases_present = [disease_names[i] for i, val in enumerate(label) if val == 1]\n",
    "        title = ', '.join(diseases_present) if diseases_present else 'No findings'\n",
    "        ax.set_title(title[:30], fontsize=8)  # Truncate long titles\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Sample Chest X-rays with Labels', y=1.02, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1bdccd-fd0f-4303-accb-bffe832986f8",
   "metadata": {
    "id": "5b1bdccd-fd0f-4303-accb-bffe832986f8"
   },
   "source": [
    "## Step 3: Analyze label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4d246f-df2b-4569-84e5-85b73d66e804",
   "metadata": {
    "id": "6e4d246f-df2b-4569-84e5-85b73d66e804"
   },
   "outputs": [],
   "source": [
    "# Extract all labels from training set\n",
    "all_labels = np.array([train_dataset[i][1] for i in range(len(train_dataset))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4732df93-aade-4be9-8de2-4818f7ec402e",
   "metadata": {
    "id": "4732df93-aade-4be9-8de2-4818f7ec402e"
   },
   "outputs": [],
   "source": [
    "# Count positive cases for each disease\n",
    "disease_counts = all_labels.sum(axis=0)\n",
    "disease_percentages = (disease_counts / len(train_dataset)) * 100\n",
    "\n",
    "# Visualize label distribution\n",
    "plt.figure(figsize=(14, 6))\n",
    "bars = plt.bar(range(len(disease_names)), disease_counts)\n",
    "plt.xticks(range(len(disease_names)), disease_names, rotation=45, ha='right')\n",
    "plt.ylabel('Number of Positive Cases')\n",
    "plt.title('Distribution of Diseases in Training Set')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add percentage labels on bars\n",
    "for i, (bar, pct) in enumerate(zip(bars, disease_percentages)):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{pct:.1f}%', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check for class imbalance\n",
    "print(\"\\nClass Distribution:\")\n",
    "for name, count, pct in zip(disease_names, disease_counts, disease_percentages):\n",
    "    print(f\"{name:20s}: {int(count):5d} ({pct:5.2f}%)\")\n",
    "\n",
    "# Average number of conditions per image\n",
    "avg_conditions = all_labels.sum(axis=1).mean()\n",
    "print(f\"\\nAverage conditions per X-ray: {avg_conditions:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b527c79-9de2-4537-9403-0434de5a5e09",
   "metadata": {
    "id": "2b527c79-9de2-4537-9403-0434de5a5e09",
    "outputId": "d0155e21-818a-40e5-ffb9-4f17b10d4e71"
   },
   "source": [
    "## Step 4: Convert to NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a433871-5bae-4e7a-ada3-12b3ebcd721d",
   "metadata": {
    "id": "8a433871-5bae-4e7a-ada3-12b3ebcd721d"
   },
   "outputs": [],
   "source": [
    "# Convert datasets to numpy arrays\n",
    "def dataset_to_numpy(dataset):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for img, label in dataset:\n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_train, y_train = dataset_to_numpy(train_dataset)\n",
    "X_val, y_val = dataset_to_numpy(val_dataset)\n",
    "X_test, y_test = dataset_to_numpy(test_dataset)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")  # (n_samples, 28, 28, 1)\n",
    "print(f\"y_train shape: {y_train.shape}\")  # (n_samples, 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ad459c-99f8-49df-b104-0375894955fa",
   "metadata": {
    "id": "82ad459c-99f8-49df-b104-0375894955fa",
    "outputId": "d0155e21-818a-40e5-ffb9-4f17b10d4e71"
   },
   "source": [
    "## Step 5: Flatten images for dense network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fe06e5-e527-4f9f-b9f3-d60c81c2052f",
   "metadata": {
    "id": "d5fe06e5-e527-4f9f-b9f3-d60c81c2052f"
   },
   "outputs": [],
   "source": [
    "# Flatten images from (28, 28, 1) to (784,)\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_val_flat = X_val.reshape(X_val.shape[0], -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "print(f\"X_train_flat shape: {X_train_flat.shape}\")  # (n_samples, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2a8098-0079-46a3-8126-c41c25872314",
   "metadata": {
    "id": "fd2a8098-0079-46a3-8126-c41c25872314",
    "outputId": "d0155e21-818a-40e5-ffb9-4f17b10d4e71"
   },
   "source": [
    "## Step 6: Normalize pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c729cee-f7f8-4bcd-8968-69d67f63fdb3",
   "metadata": {
    "id": "7c729cee-f7f8-4bcd-8968-69d67f63fdb3"
   },
   "outputs": [],
   "source": [
    "# Normalize to [0, 1] range\n",
    "X_train_norm = X_train_flat.astype('float32') / 255.0\n",
    "X_val_norm = X_val_flat.astype('float32') / 255.0\n",
    "X_test_norm = X_test_flat.astype('float32') / 255.0\n",
    "\n",
    "print(f\"Normalized range: [{X_train_norm.min()}, {X_train_norm.max()}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efba60a-ded3-404d-a2a8-d9a7d984d53c",
   "metadata": {
    "id": "6efba60a-ded3-404d-a2a8-d9a7d984d53c",
    "outputId": "d0155e21-818a-40e5-ffb9-4f17b10d4e71"
   },
   "source": [
    "## Step 7: Verify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cf8d00-057e-405f-b995-dac4751e2956",
   "metadata": {
    "id": "93cf8d00-057e-405f-b995-dac4751e2956"
   },
   "outputs": [],
   "source": [
    "print(\"\\n=== Data Summary ===\")\n",
    "print(f\"Training set: {X_train_norm.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val_norm.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test_norm.shape[0]} samples\")\n",
    "print(f\"Input features: {X_train_norm.shape[1]}\")\n",
    "print(f\"Output labels: {y_train.shape[1]}\")\n",
    "print(f\"Label type: {y_train.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899042d0-3116-435f-a176-9a5eda12f0d3",
   "metadata": {
    "id": "899042d0-3116-435f-a176-9a5eda12f0d3",
    "outputId": "989f916a-775c-429a-dc8f-cb40c187edf2"
   },
   "source": [
    "## Step 8: Define model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83f6db7-73ea-45b2-b3ab-3409d2c340a1",
   "metadata": {
    "id": "b83f6db7-73ea-45b2-b3ab-3409d2c340a1"
   },
   "outputs": [],
   "source": [
    "# Define input shape\n",
    "input_dim = X_train_norm.shape[1]  # 784\n",
    "output_dim = y_train.shape[1]  # 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010b6bbf-e3cd-40c6-9c4d-ef5ba65acd72",
   "metadata": {
    "id": "010b6bbf-e3cd-40c6-9c4d-ef5ba65acd72"
   },
   "outputs": [],
   "source": [
    "# Build the dense neural network\n",
    "model = keras.Sequential([\n",
    "    # Explicit Input layer\n",
    "    keras.Input(shape=(input_dim,)),\n",
    "\n",
    "    # First hidden block\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "\n",
    "    # Hidden layer 1\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "\n",
    "    # Hidden layer 2\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.1),\n",
    "\n",
    "    # Hidden layer 3\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "\n",
    "    # Output layer (multi-label classification)\n",
    "    keras.layers.Dense(output_dim, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f961a74-c77d-4880-adf8-a588c04ba1b6",
   "metadata": {
    "id": "8f961a74-c77d-4880-adf8-a588c04ba1b6"
   },
   "outputs": [],
   "source": [
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61551e72-30a5-48d3-8ac9-8da99dee3c18",
   "metadata": {
    "id": "61551e72-30a5-48d3-8ac9-8da99dee3c18"
   },
   "outputs": [],
   "source": [
    "# Calculate total parameters\n",
    "total_params = model.count_params()\n",
    "print(f\"\\nTotal trainable parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d8e1e3-a5ee-41d8-8e89-d7af2a4428b4",
   "metadata": {
    "id": "b4d8e1e3-a5ee-41d8-8e89-d7af2a4428b4"
   },
   "source": [
    "### Architecture explanation:\n",
    "- **Input**: 784 features (28×28 flattened image)\n",
    "- **Layer 1**: 512 neurons with ReLU, Batch Normalization, 50% dropout\n",
    "- **Layer 2**: 256 neurons with ReLU, Batch Normalization, 40% dropout\n",
    "- **Layer 3**: 128 neurons with ReLU, Batch Normalization, 30% dropout\n",
    "- **Layer 4**: 64 neurons with ReLU, 20% dropout\n",
    "- **Output**: 14 neurons with sigmoid activation (independent binary predictions)\n",
    "\n",
    "**Why sigmoid?** Each disease is independent, so you use sigmoid for each output (not softmax)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6sZsmUuwaPdQ",
   "metadata": {
    "id": "6sZsmUuwaPdQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "def multilabel_accuracy(y_true, y_pred):\n",
    "    threshold = tf.cast(0.5, dtype=y_pred.dtype)\n",
    "    y_pred_binary = tf.cast(y_pred > threshold, dtype=y_pred.dtype)\n",
    "    correct_predictions = tf.equal(tf.cast(y_true, dtype=tf.float32), y_pred_binary)\n",
    "    return tf.reduce_mean(tf.cast(correct_predictions, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35673b7-a05c-4b0d-ac03-b7525f83c0b5",
   "metadata": {
    "id": "d35673b7-a05c-4b0d-ac03-b7525f83c0b5"
   },
   "source": [
    "## Step 9: Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6ff8d5-54da-4e2f-b4a4-97009a1f4837",
   "metadata": {
    "id": "5a6ff8d5-54da-4e2f-b4a4-97009a1f4837"
   },
   "outputs": [],
   "source": [
    "# For multi-label classification, use binary crossentropy\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        multilabel_accuracy,\n",
    "        keras.metrics.AUC(name='auc', multi_label=True),\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89e781f-f90f-4c35-b0bf-1f8b33867513",
   "metadata": {
    "id": "b89e781f-f90f-4c35-b0bf-1f8b33867513",
    "outputId": "7c7c970f-9707-4504-88cb-8dcd431760d8"
   },
   "source": [
    "## Step 10: Calculate class weights (Handle imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f3e63-c2db-4089-b7f2-e4738dc4a31a",
   "metadata": {
    "id": "5d9f3e63-c2db-4089-b7f2-e4738dc4a31a"
   },
   "outputs": [],
   "source": [
    "# Calculate positive class frequency for each label\n",
    "pos_freq = y_train.sum(axis=0) / len(y_train)\n",
    "neg_freq = 1 - pos_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059188c8-26e5-43d7-9cc2-5d28d1c9455d",
   "metadata": {
    "id": "059188c8-26e5-43d7-9cc2-5d28d1c9455d"
   },
   "outputs": [],
   "source": [
    "# Calculate class weights (inverse frequency)\n",
    "pos_weight = neg_freq / pos_freq\n",
    "print(\"Positive class weights per disease:\")\n",
    "for name, weight in zip(disease_names, pos_weight):\n",
    "    print(f\"{name:20s}: {weight:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51101098-73d8-4bdb-872a-6b72a3d34df7",
   "metadata": {
    "id": "51101098-73d8-4bdb-872a-6b72a3d34df7"
   },
   "outputs": [],
   "source": [
    "# Create a weighted binary crossentropy loss\n",
    "def weighted_binary_crossentropy(pos_weight):\n",
    "    def loss(y_true, y_pred):\n",
    "        # Clip predictions to prevent log(0)\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
    "\n",
    "        # Calculate weighted loss\n",
    "        loss = -tf.reduce_mean(\n",
    "            pos_weight * y_true * tf.math.log(y_pred) +\n",
    "            (1 - y_true) * tf.math.log(1 - y_pred)\n",
    "        )\n",
    "        return loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553b87dd-3d34-4676-a492-eea7f0e40d9f",
   "metadata": {
    "id": "553b87dd-3d34-4676-a492-eea7f0e40d9f"
   },
   "outputs": [],
   "source": [
    "# Recompile with weighted loss\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=weighted_binary_crossentropy(pos_weight),\n",
    "    metrics=[\n",
    "        multilabel_accuracy,\n",
    "        keras.metrics.AUC(name='auc', multi_label=True),\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbd6be3-9987-4a0d-8a81-5b4cb7d28046",
   "metadata": {
    "id": "bbbd6be3-9987-4a0d-8a81-5b4cb7d28046",
    "outputId": "7c7c970f-9707-4504-88cb-8dcd431760d8"
   },
   "source": [
    "## Step 11: Set up callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27296fb-34f2-4af0-8c6e-06865819e2d0",
   "metadata": {
    "id": "f27296fb-34f2-4af0-8c6e-06865819e2d0"
   },
   "outputs": [],
   "source": [
    "# Early stopping\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_auc',\n",
    "    patience=15,\n",
    "    mode='max',\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Learning rate reduction\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Model checkpoint\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    'best_chestmnist_model.keras',\n",
    "    monitor='val_auc',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad25ef95-49f2-4de5-b967-6c5749e34459",
   "metadata": {
    "id": "ad25ef95-49f2-4de5-b967-6c5749e34459",
    "outputId": "b8631b6d-a151-49fc-a46e-12637f888f4d"
   },
   "source": [
    "## Step 12: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b90eb1-3454-4b39-a554-68d154ff82de",
   "metadata": {
    "id": "49b90eb1-3454-4b39-a554-68d154ff82de"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_norm, y_train,\n",
    "    validation_data=(X_val_norm, y_val),\n",
    "    epochs=30,\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stopping, reduce_lr, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining completed!\")\n",
    "print(f\"Best epoch: {np.argmax(history.history['val_auc']) + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0893dbf5-e8d2-40f0-9d9b-e4e1cf2a9a7a",
   "metadata": {
    "id": "0893dbf5-e8d2-40f0-9d9b-e4e1cf2a9a7a",
    "outputId": "b8631b6d-a151-49fc-a46e-12637f888f4d"
   },
   "source": [
    "## Step 13: Visualize training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72764d93-ee92-4971-aea0-aad4d103629b",
   "metadata": {
    "id": "72764d93-ee92-4971-aea0-aad4d103629b"
   },
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Accuracy\n",
    "axes[0, 0].plot(history.history['multilabel_accuracy'], label='Train')\n",
    "axes[0, 0].plot(history.history['val_multilabel_accuracy'], label='Validation')\n",
    "axes[0, 0].set_title('Model Accuracy')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('multilabel_accuracy')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Loss\n",
    "axes[0, 1].plot(history.history['loss'], label='Train')\n",
    "axes[0, 1].plot(history.history['val_loss'], label='Validation')\n",
    "axes[0, 1].set_title('Model Loss')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# AUC\n",
    "axes[1, 0].plot(history.history['auc'], label='Train')\n",
    "axes[1, 0].plot(history.history['val_auc'], label='Validation')\n",
    "axes[1, 0].set_title('Model AUC')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('AUC')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Precision & Recall\n",
    "axes[1, 1].plot(history.history['precision'], label='Train Precision')\n",
    "axes[1, 1].plot(history.history['val_precision'], label='Val Precision')\n",
    "axes[1, 1].plot(history.history['recall'], label='Train Recall')\n",
    "axes[1, 1].plot(history.history['val_recall'], label='Val Recall')\n",
    "axes[1, 1].set_title('Precision & Recall')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Score')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705062bb-5eba-49e5-83e3-d64954e3828d",
   "metadata": {
    "id": "705062bb-5eba-49e5-83e3-d64954e3828d",
    "outputId": "ba745d80-552e-40ff-a8bd-94e1a3941ce8"
   },
   "source": [
    "## Step 14: Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360e9972-dd5e-42fc-8b2c-a895da38120c",
   "metadata": {
    "id": "360e9972-dd5e-42fc-8b2c-a895da38120c"
   },
   "outputs": [],
   "source": [
    "# Predict on test set (probabilities)\n",
    "y_pred_prob = model.predict(X_test_norm)\n",
    "\n",
    "# Convert probabilities to binary predictions (threshold = 0.5)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "print(f\"Prediction probabilities shape: {y_pred_prob.shape}\")\n",
    "print(f\"Binary predictions shape: {y_pred.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8850187-dd9d-4caf-a454-574729a410da",
   "metadata": {
    "id": "e8850187-dd9d-4caf-a454-574729a410da",
    "outputId": "ba745d80-552e-40ff-a8bd-94e1a3941ce8"
   },
   "source": [
    "## Step 15: Calculate overall metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ddb833-9c30-47aa-9f4e-3d8b6e28a330",
   "metadata": {
    "id": "28ddb833-9c30-47aa-9f4e-3d8b6e28a330"
   },
   "outputs": [],
   "source": [
    "# Calculate overall metrics\n",
    "test_loss, test_acc, test_auc, test_precision, test_recall = model.evaluate(\n",
    "    X_test_norm, y_test, verbose=0\n",
    ")\n",
    "\n",
    "print(\"\\n=== Overall Test Set Performance ===\")\n",
    "print(f\"Loss: {test_loss:.4f}\")\n",
    "print(f\"Accuracy: {test_acc:.4f}\")\n",
    "print(f\"AUC: {test_auc:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall: {test_recall:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140b06ed-9e6f-43ff-8251-ffbc8454ebdd",
   "metadata": {
    "id": "140b06ed-9e6f-43ff-8251-ffbc8454ebdd",
    "outputId": "ba745d80-552e-40ff-a8bd-94e1a3941ce8"
   },
   "source": [
    "## Step 16: Calculate per-disease performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b76956-b28b-480a-ae23-b5c2b4ec7a5a",
   "metadata": {
    "id": "c8b76956-b28b-480a-ae23-b5c2b4ec7a5a"
   },
   "outputs": [],
   "source": [
    "# Calculate per-disease metrics\n",
    "print(\"\\n=== Per-Disease Performance ===\")\n",
    "print(f\"{'Disease':<20s} {'AUC':>6s} {'Precision':>10s} {'Recall':>8s} {'F1':>6s} {'Support':>8s}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "per_disease_metrics = []\n",
    "for i, disease in enumerate(disease_names):\n",
    "    # AUC for this disease\n",
    "    auc = roc_auc_score(y_test[:, i], y_pred_prob[:, i])\n",
    "\n",
    "    # Precision, Recall, F1\n",
    "    tp = ((y_test[:, i] == 1) & (y_pred[:, i] == 1)).sum()\n",
    "    fp = ((y_test[:, i] == 0) & (y_pred[:, i] == 1)).sum()\n",
    "    fn = ((y_test[:, i] == 1) & (y_pred[:, i] == 0)).sum()\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    support = y_test[:, i].sum()\n",
    "\n",
    "    print(f\"{disease:<20s} {auc:>6.3f} {precision:>10.3f} {recall:>8.3f} {f1:>6.3f} {int(support):>8d}\")\n",
    "\n",
    "    per_disease_metrics.append({\n",
    "        'disease': disease,\n",
    "        'auc': auc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'support': int(support)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efe49cf-bc49-41ed-a112-60466dc07d4f",
   "metadata": {
    "id": "0efe49cf-bc49-41ed-a112-60466dc07d4f",
    "outputId": "3a57ab34-c540-44de-d8ad-1e9b5aa72a80"
   },
   "source": [
    "## Step 17: Visualize confusion matrices for each disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99588625-c0eb-4ac7-bb5a-ae09986553bb",
   "metadata": {
    "id": "99588625-c0eb-4ac7-bb5a-ae09986553bb"
   },
   "outputs": [],
   "source": [
    "# Calculate multilabel confusion matrix\n",
    "cm = multilabel_confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualize confusion matrices for first 4 diseases\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(4):\n",
    "    sns.heatmap(cm[i], annot=True, fmt='d', cmap='Blues', ax=axes[i],\n",
    "                xticklabels=['Negative', 'Positive'],\n",
    "                yticklabels=['Negative', 'Positive'])\n",
    "    axes[i].set_title(f'{disease_names[i]} Confusion Matrix')\n",
    "    axes[i].set_ylabel('Actual')\n",
    "    axes[i].set_xlabel('Predicted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d23889-974c-481e-8be6-df2f20a14915",
   "metadata": {
    "id": "b3d23889-974c-481e-8be6-df2f20a14915",
    "outputId": "3a57ab34-c540-44de-d8ad-1e9b5aa72a80"
   },
   "source": [
    "## Step 18: Plot ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61defb0-3014-4ab1-8ba0-9cebdf1ba327",
   "metadata": {
    "id": "b61defb0-3014-4ab1-8ba0-9cebdf1ba327"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Plot ROC curves for selected diseases\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Select 6 most common diseases\n",
    "selected_indices = np.argsort(y_test.sum(axis=0))[-6:]\n",
    "\n",
    "for idx, i in enumerate(selected_indices):\n",
    "    fpr, tpr, _ = roc_curve(y_test[:, i], y_pred_prob[:, i])\n",
    "    auc_score = roc_auc_score(y_test[:, i], y_pred_prob[:, i])\n",
    "\n",
    "    axes[idx].plot(fpr, tpr, color='darkorange', lw=2,\n",
    "                   label=f'ROC curve (AUC = {auc_score:.3f})')\n",
    "    axes[idx].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    axes[idx].set_xlim([0.0, 1.0])\n",
    "    axes[idx].set_ylim([0.0, 1.05])\n",
    "    axes[idx].set_xlabel('False Positive Rate')\n",
    "    axes[idx].set_ylabel('True Positive Rate')\n",
    "    axes[idx].set_title(f'{disease_names[i]} ROC Curve')\n",
    "    axes[idx].legend(loc=\"lower right\")\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f85d22-98a7-442f-9c5f-3a6b7f8ef9a9",
   "metadata": {
    "id": "66f85d22-98a7-442f-9c5f-3a6b7f8ef9a9",
    "outputId": "3a57ab34-c540-44de-d8ad-1e9b5aa72a80"
   },
   "source": [
    "## Step 19: Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2b99f2-7b9d-40d2-ad08-c052b5dcbcec",
   "metadata": {
    "id": "5e2b99f2-7b9d-40d2-ad08-c052b5dcbcec"
   },
   "outputs": [],
   "source": [
    "# Visualize some predictions\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "\n",
    "for idx, ax in enumerate(axes.flat):\n",
    "    if idx < 12:\n",
    "        # Get random test sample\n",
    "        i = np.random.randint(0, len(X_test))\n",
    "        img = X_test[i].squeeze()\n",
    "        true_labels = y_test[i]\n",
    "        pred_probs = y_pred_prob[i]\n",
    "\n",
    "        # Display image\n",
    "        ax.imshow(img, cmap='gray')\n",
    "\n",
    "        # Get disease names\n",
    "        true_diseases = [disease_names[j] for j, val in enumerate(true_labels) if val == 1]\n",
    "        pred_diseases = [(disease_names[j], pred_probs[j])\n",
    "                        for j in range(len(pred_probs)) if pred_probs[j] > 0.5]\n",
    "\n",
    "        # Create title\n",
    "        true_str = ', '.join(true_diseases) if true_diseases else 'No findings'\n",
    "        pred_str = ', '.join([f\"{d}({p:.2f})\" for d, p in pred_diseases]) if pred_diseases else 'No findings'\n",
    "\n",
    "        title = f\"True: {true_str[:30]}\\nPred: {pred_str[:30]}\"\n",
    "        ax.set_title(title, fontsize=8)\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Sample Predictions (Probability > 0.5)', y=1.02, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dafbf3-2476-47e0-9f19-a43ef1f7f8b1",
   "metadata": {
    "id": "47dafbf3-2476-47e0-9f19-a43ef1f7f8b1",
    "outputId": "b9a269ea-2a01-4870-9e50-916f3566e78b"
   },
   "source": [
    "## Step 20: Save and deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f81d2b-8a69-4a84-943f-42724ae1ee4e",
   "metadata": {
    "id": "39f81d2b-8a69-4a84-943f-42724ae1ee4e"
   },
   "outputs": [],
   "source": [
    "# Save entire model\n",
    "model.save('chestmnist_dnn_model.keras')\n",
    "\n",
    "# Save model architecture as JSON\n",
    "model_json = model.to_json()\n",
    "with open('model_architecture.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Save weights separately\n",
    "model.save_weights('model_weights.weights.h5')\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad907cf6-a939-488b-a9d4-e4c25af47ec6",
   "metadata": {
    "id": "ad907cf6-a939-488b-a9d4-e4c25af47ec6"
   },
   "outputs": [],
   "source": [
    "### Load and Use Model\n",
    "\n",
    "# Load model\n",
    "loaded_model = keras.models.load_model(\n",
    "    'chestmnist_dnn_model.keras',\n",
    "    custom_objects={'loss': weighted_binary_crossentropy(pos_weight), 'multilabel_accuracy': multilabel_accuracy}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2087ed-376a-4652-b416-ea31c36f91b2",
   "metadata": {
    "id": "1e2087ed-376a-4652-b416-ea31c36f91b2"
   },
   "outputs": [],
   "source": [
    "# Make prediction on new data\n",
    "from PIL import Image\n",
    "\n",
    "def predict_diseases(model, image):\n",
    "    \"\"\"\n",
    "    Predict diseases from a single chest X-ray image\n",
    "\n",
    "    Args:\n",
    "        model: trained Keras model\n",
    "        image: PIL Image or numpy array of shape (28, 28, 1)\n",
    "\n",
    "    Returns:\n",
    "        dict: disease names and probabilities\n",
    "    \"\"\"\n",
    "    # Convert PIL Image to NumPy array if necessary\n",
    "    if isinstance(image, Image.Image):\n",
    "        image = np.array(image)\n",
    "\n",
    "    # Preprocess\n",
    "    img_flat = image.reshape(1, -1).astype('float32') / 255.0\n",
    "\n",
    "    # Predict\n",
    "    probs = model.predict(img_flat, verbose=0)[0]\n",
    "\n",
    "    # Create results dictionary\n",
    "    results = {}\n",
    "    for disease, prob in zip(disease_names, probs):\n",
    "        results[disease] = float(prob)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f32447-e4ee-4e29-bfd0-2fde0742a22e",
   "metadata": {
    "id": "03f32447-e4ee-4e29-bfd0-2fde0742a22e"
   },
   "outputs": [],
   "source": [
    "# Test prediction function\n",
    "test_img, test_label = test_dataset[0]\n",
    "predictions = predict_diseases(loaded_model, test_img)\n",
    "\n",
    "print(\"\\nPrediction Results:\")\n",
    "for disease, prob in sorted(predictions.items(), key=lambda x: x[1], reverse=True):\n",
    "    if prob > 0.5:\n",
    "        print(f\"{disease:20s}: {prob:.3f} ({'POSITIVE' if prob > 0.5 else 'negative'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4630e2aa-42c6-4acc-82fd-aed2d1a0d65f",
   "metadata": {
    "id": "4630e2aa-42c6-4acc-82fd-aed2d1a0d65f",
    "outputId": "857c02fe-e6b4-4c6c-96e1-823afaeb93d8"
   },
   "source": [
    "# Exercises\n",
    "In Step 8, you built a neural network. Given below are two more architectures for neural networks. One is a deeper network with more layers. Another one is a wider network with less layers. Replace the existing network with these networks, one after the other and observe the changes in the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bb5ba2-260a-4b44-ab4f-799b6ee43e56",
   "metadata": {
    "id": "c3bb5ba2-260a-4b44-ab4f-799b6ee43e56",
    "outputId": "857c02fe-e6b4-4c6c-96e1-823afaeb93d8"
   },
   "source": [
    "## Exercise 1: Use the deeper network architecture variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6477a521-fe6e-46ae-9453-8896475e297f",
   "metadata": {
    "id": "6477a521-fe6e-46ae-9453-8896475e297f"
   },
   "outputs": [],
   "source": [
    "# Deeper network\n",
    "model_deep = keras.Sequential([\n",
    "    keras.layers.Dense(1024, activation='relu', input_shape=(input_dim,)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(output_dim, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8ce966-c493-4e3c-af31-06f2a7196564",
   "metadata": {
    "id": "8b8ce966-c493-4e3c-af31-06f2a7196564",
    "outputId": "857c02fe-e6b4-4c6c-96e1-823afaeb93d8"
   },
   "source": [
    "## Exercise 2: Use the wider network architecture variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c2da20-dd22-4097-a5aa-fff3c0f7f33c",
   "metadata": {
    "id": "62c2da20-dd22-4097-a5aa-fff3c0f7f33c"
   },
   "outputs": [],
   "source": [
    "# Wider network\n",
    "model_wide = keras.Sequential([\n",
    "    keras.layers.Dense(1024, activation='relu', input_shape=(input_dim,)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1024, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(output_dim, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5c12ed-4395-4801-aec5-ae9b3b6d2ad2",
   "metadata": {
    "id": "7f5c12ed-4395-4801-aec5-ae9b3b6d2ad2"
   },
   "source": [
    "# Congratulations!\n",
    "\n",
    "You have successfully completed this lab on how to load and preprocess medical imaging data using MedMNIST, design a dense neural network for multi-label classification, handle medical image datasets involving multiple simultaneous conditions, train models with appropriate hyperparameters optimized for medical imaging, and evaluate multi-label classification performance using clinically relevant metrics.\n",
    "\n",
    "## Authors\n",
    "\n",
    "Ramesh Sannareddy\n",
    "\n",
    "Copyright © 2025 SkillUp. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
