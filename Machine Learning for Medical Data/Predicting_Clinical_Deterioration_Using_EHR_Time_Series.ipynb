{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "## Predicting Clinical Deterioration Using EHR Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ca9654-9aaa-4908-b017-da14b4ca2b8a",
   "metadata": {},
   "source": [
    "Time estimate: **20** minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this lab, you will be able to:\n",
    "\n",
    " - Explain the structure and characteristics of time-series electronic health record (EHR) data\n",
    " - Train a Long Short-Term Memory (LSTM) neural network to predict ICU admission risk\n",
    " - Evaluate model performance and interpret results using standard classification metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2eabb5-ed96-474f-a869-2dbdc7cb93a9",
   "metadata": {},
   "source": [
    "## What you will do in this lab\n",
    "\n",
    "In this lab, you will use a simulated time-series dataset of patient vital signs to develop and test an LSTM model.\n",
    "\n",
    "You will:\n",
    "\n",
    " - Load the time-series EHR data into a dataframe\n",
    " - Explore and understand the structure of the time-series data\n",
    " - Prepare data sequences suitable for model training\n",
    " - Split the dataset into training and testing subsets\n",
    " - Build and train an LSTM neural network model\n",
    " - Evaluate model performance and generate predictions\n",
    " - Visualize results using a confusion matrix and Receiver Operating Characteristic (ROC) curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Clinical deterioration refers to the worsening of a patient's condition over time. Early detection of deterioration allows healthcare teams to intervene before critical events such as cardiac arrest or respiratory failure occur.\n",
    "\n",
    "In hospitals, patients are continuously monitored with vital signs recorded at regular intervals. By analyzing these time-series patterns, machine learning models can identify subtle changes that may indicate impending deterioration.\n",
    "\n",
    "Imagine a patient admitted to a general ward. Assume their vital signs are recorded every hour:\n",
    "\n",
    "- Heart rate starts at 75 bpm, gradually increases to 110 bpm\n",
    "- Blood pressure drops from 120/80 to 90/60\n",
    "- Oxygen saturation decreases from 98% to 92%\n",
    "\n",
    "These trends suggest the patient may need intensive care. \n",
    "\n",
    "The goal is to predict early whether a patient will require ICU admission based on sequential vital sign measurements.\n",
    "\n",
    "### Why Long Short-Term Memory (LSTM)?\n",
    "\n",
    "Traditional machine learning models such as Random Forest treat each data point independently. They cannot capture temporal dependencies, which is how one measurement relates to previous measurements over time.\n",
    "\n",
    "LSTM is a type of Recurrent Neural Network (RNN) specifically designed for sequential data:\n",
    "\n",
    "**Memory Cells**: LSTM can remember important patterns from earlier time steps and use them to make predictions.\n",
    "\n",
    "**Temporal Dependencies**: It understands that vital signs at time t=5 may depend on values at t=1, t=2, t=3, t=4.\n",
    "\n",
    "**Gradient Flow**: Unlike simple RNNs, LSTMs avoid the \"vanishing gradient\" problem, allowing them to learn long-term patterns.\n",
    "\n",
    "Example: If a patient's heart rate has been steadily increasing over the past 6 hours, LSTM recognizes this trend and uses it for prediction. A traditional model would only see the current heart rate value without context.\n",
    "\n",
    "### Assessing Accuracy and clinical utility\n",
    "\n",
    "Accuracy: How well does the model classify patients into correct categories? (e.g., 88% correct).\n",
    "\n",
    "Clinical utility: Is the model actually useful in practice?\n",
    "\n",
    "Example: A model may have high accuracy but if it misses too many patients who actually need ICU care (low sensitivity), it could lead to preventable adverse outcomes.\n",
    "\n",
    "Metrics such as Precision, Recall, Sensitivity, Specificity, and ROC-AUC help us assess whether the model is clinically valuable.\n",
    "\n",
    "**Sensitivity (Recall)**: Of all patients who needed ICU, how many did the model identify?\n",
    "\n",
    "**Specificity**: Of all patients who did not need ICU, how many did the model correctly classify?\n",
    "\n",
    "**ROC-AUC**: Measures the model's ability to distinguish between ICU and non-ICU patients across different threshold settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01470afe-568c-4185-a431-41050023a1ab",
   "metadata": {},
   "source": [
    "## About the dataset\n",
    "\n",
    "In this lab, you will use a simulated time-series dataset representing patient vital signs collected over time in a hospital setting.\n",
    "\n",
    "This dataset contains sequential measurements of patient vital signs recorded at regular intervals during hospital stays. Each patient has multiple time-stamped observations, making it suitable for time-series forecasting of clinical deterioration. The goal is to predict whether a patient will require ICU admission based on their vital sign trajectories.\n",
    "\n",
    "Column Descriptions\n",
    "\n",
    "1. **patient_id** - Unique identifier for each patient in the hospital system.\n",
    "\n",
    "2. **time_step** - Sequential time point representing when the measurement was taken (e.g., hourly intervals).\n",
    "\n",
    "3. **heart_rate** - Heart rate in beats per minute (bpm). Normal range: 60-100 bpm.\n",
    "\n",
    "4. **systolic_bp** - Systolic blood pressure in mmHg. Normal range: 90-120 mmHg.\n",
    "\n",
    "5. **diastolic_bp** - Diastolic blood pressure in mmHg. Normal range: 60-80 mmHg.\n",
    "\n",
    "6. **respiratory_rate** - Breathing rate in breaths per minute. Normal range: 12-20 breaths/min.\n",
    "\n",
    "7. **temperature** - Body temperature in degrees Celsius. Normal range: 36.5-37.5°C.\n",
    "\n",
    "8. **spo2** - Oxygen saturation percentage. Normal range: 95-100%.\n",
    "\n",
    "9. **icu_admission** - Binary target variable (0 = No ICU admission, 1 = ICU admission required).\n",
    "\n",
    "### Time-series characteristics\n",
    "\n",
    "- Each patient has multiple sequential observations (typically 10-20 time steps)\n",
    "- Measurements are taken at regular intervals during hospital stay\n",
    "- The target (icu_admission) is assigned to the entire patient sequence\n",
    "- Temporal patterns in vital signs provide predictive signals for deterioration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "For this lab, you will be using the following libraries:\n",
    "\n",
    "*   [`pandas`](https://pandas.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for managing the data\n",
    "*   [`numpy`](https://numpy.org/) for numerical operations and array manipulation\n",
    "*   [`sklearn`](https://scikit-learn.org/stable/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for data preprocessing and evaluation metrics\n",
    "*   [`tensorflow/keras`](https://www.tensorflow.org/) for building and training LSTM neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "### Installing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install scikit-learn\n",
    "!pip install tensorflow\n",
    "!pip install matplotlib\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas for data manipulation\n",
    "import pandas as pd\n",
    "# Import numpy for numerical operations\n",
    "import numpy as np\n",
    "\n",
    "# Import preprocessing tools from scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Import evaluation metrics from scikit-learn\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report, \n",
    "    roc_curve, auc, recall_score\n",
    ")\n",
    "\n",
    "# Import TensorFlow and Keras for building the LSTM model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Import matplotlib and seaborn for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(\"Ready to begin clinical deterioration prediction analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Step 1: Load the data from a csv file into a dataframe\n",
    "\n",
    "Since time-series vital signs data with patient_id and time_step structure is not readily available publicly, you will first generate a synthetic dataset that simulates realistic hospital vital signs monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "Load the data from a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c308f90b-d97b-47d0-a10a-d211ad4531bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://advanced-machine-learning-for-medical-data-8e1579.gitlab.io/labs/lab9/patient_vitals_hospital1.csv\")\n",
    "print(f\"Total records: {df.shape[0]}\")\n",
    "print(f\"Number of patients: {df.patient_id.nunique()}\")\n",
    "print(f\"Time steps per patient: {df.shape[0]/df.patient_id.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first 5 rows to see the time-series structure\n",
    "# Notice how each patient has multiple sequential measurements\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "Let's find out the structure of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset dimensions\n",
    "print(f'Number of rows: {df.shape[0]}')\n",
    "print(f'Number of columns: {df.shape[1]}')\n",
    "print(f'\\nColumns: {list(df.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "### Basic statistical information about features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic statistical information about each vital sign\n",
    "print(\"=== BASIC STATISTICS FOR ALL FEATURES ===\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "Check the distribution of the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution\n",
    "# In medical datasets, it is important to check if classes are balanced\n",
    "print(\"ICU Admission Distribution:\")\n",
    "print(df.groupby('patient_id')['icu_admission'].first().value_counts())\n",
    "print(\"\\nPercentage:\")\n",
    "print(df.groupby('patient_id')['icu_admission'].first().value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## Step 2: Explore the time-series structure\n",
    "\n",
    "Before building the model, you need to understand how the time-series data is organized. Each patient has multiple sequential measurements, and you will visualize these patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one patient who required ICU admission\n",
    "icu_patient = df[df['icu_admission'] == 1]['patient_id'].iloc[0]\n",
    "icu_patient_data = df[df['patient_id'] == icu_patient]\n",
    "\n",
    "# Select one stable patient who did not require ICU\n",
    "stable_patient = df[df['icu_admission'] == 0]['patient_id'].iloc[0]\n",
    "stable_patient_data = df[df['patient_id'] == stable_patient]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize vital sign trends for both patients\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 10))\n",
    "fig.suptitle('Comparison of Vital Sign Trends: ICU vs Stable Patient', fontsize=16)\n",
    "\n",
    "vital_signs = ['heart_rate', 'systolic_bp', 'respiratory_rate', 'temperature', 'spo2', 'diastolic_bp']\n",
    "titles = ['Heart Rate (bpm)', 'Systolic BP (mmHg)', 'Respiratory Rate (breaths/min)', \n",
    "          'Temperature (°C)', 'SpO2 (%)', 'Diastolic BP (mmHg)']\n",
    "\n",
    "for idx, (vital, title) in enumerate(zip(vital_signs, titles)):\n",
    "    row = idx // 2\n",
    "    col = idx % 2\n",
    "    \n",
    "    axes[row, col].plot(icu_patient_data['time_step'], icu_patient_data[vital], \n",
    "                        marker='o', label='ICU Patient', color='blue')\n",
    "    axes[row, col].plot(stable_patient_data['time_step'], stable_patient_data[vital], \n",
    "                        marker='s', label='Stable Patient', color='orange')\n",
    "    axes[row, col].set_xlabel('Time Step (hours)')\n",
    "    axes[row, col].set_ylabel(title)\n",
    "    axes[row, col].legend()\n",
    "    axes[row, col].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice how the ICU patient shows deteriorating trends:\")\n",
    "print(\"- Heart rate increases over time\")\n",
    "print(\"- Blood pressure decreases\")\n",
    "print(\"- Oxygen saturation (SpO2) decreases\")\n",
    "print(\"\\nThe stable patient maintains relatively constant vital signs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## Step 3: Prepare time-series sequences\n",
    "\n",
    "LSTM models require data in a specific 3D format: (samples, time_steps, features)\n",
    "\n",
    "- samples: Number of patients\n",
    "- time_steps: Number of sequential measurements per patient\n",
    "- features: Number of vital signs measured\n",
    "\n",
    "You will reshape the data to fit this structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature columns (vital signs)\n",
    "feature_columns = ['heart_rate', 'systolic_bp', 'diastolic_bp', \n",
    "                   'respiratory_rate', 'temperature', 'spo2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique patient IDs\n",
    "patient_ids = df['patient_id'].unique()\n",
    "print(f\"Number of unique patients: {len(patient_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences for each patient\n",
    "# Each sequence contains all time steps for one patient\n",
    "X_sequences = []\n",
    "y_labels = []\n",
    "\n",
    "for patient_id in patient_ids:\n",
    "    # Get all measurements for this patient\n",
    "    patient_data = df[df['patient_id'] == patient_id].sort_values('time_step')\n",
    "    \n",
    "    # Extract the vital signs as features\n",
    "    sequence = patient_data[feature_columns].values\n",
    "    X_sequences.append(sequence)\n",
    "    \n",
    "    # Extract the label (same for all time steps of a patient)\n",
    "    label = patient_data['icu_admission'].iloc[0]\n",
    "    y_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to numpy arrays\n",
    "X = np.array(X_sequences)\n",
    "y = np.array(y_labels)\n",
    "\n",
    "print(f\"Shape of X (input sequences): {X.shape}\")\n",
    "print(f\"  - Number of patients: {X.shape[0]}\")\n",
    "print(f\"  - Time steps per patient: {X.shape[1]}\")\n",
    "print(f\"  - Number of features (vital signs): {X.shape[2]}\")\n",
    "print(f\"\\nShape of y (target labels): {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "### Normalize the features\n",
    "\n",
    "Neural networks perform better when features are normalized (scaled to similar ranges). You will use StandardScaler to standardize each vital sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X to 2D for scaling (samples * time_steps, features)\n",
    "n_samples, n_timesteps, n_features = X.shape\n",
    "X_reshaped = X.reshape(-1, n_features)\n",
    "\n",
    "print(f\"Original shape: {X.shape}\")\n",
    "print(f\"Reshaped for scaling: {X_reshaped.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply StandardScaler\n",
    "# This transforms each feature to have mean=0 and standard deviation=1\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_reshaped)\n",
    "\n",
    "# Reshape back to 3D (samples, time_steps, features)\n",
    "X_scaled = X_scaled.reshape(n_samples, n_timesteps, n_features)\n",
    "\n",
    "print(f\"Scaled data shape: {X_scaled.shape}\")\n",
    "print(\"\\nFeatures have been normalized for optimal LSTM training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-34",
   "metadata": {},
   "source": [
    "## Step 4: Split the dataset\n",
    "\n",
    "You will split the data into training and testing sets (80:20 ratio) while maintaining the class distribution using stratification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "# stratify=y ensures both sets have similar proportions of ICU vs non-ICU patients\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training set:\")\n",
    "print(f\"  - Number of patients: {X_train.shape[0]}\")\n",
    "print(f\"  - ICU admissions: {np.sum(y_train == 1)}\")\n",
    "print(f\"  - No ICU admissions: {np.sum(y_train == 0)}\")\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "print(f\"  - Number of patients: {X_test.shape[0]}\")\n",
    "print(f\"  - ICU admissions: {np.sum(y_test == 1)}\")\n",
    "print(f\"  - No ICU admissions: {np.sum(y_test == 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-36",
   "metadata": {},
   "source": [
    "## Step 5: Build and train an LSTM model\n",
    "\n",
    "Now you will build a deep learning model using LSTM layers. LSTM networks are designed to learn patterns in sequential data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-37",
   "metadata": {},
   "source": [
    "### Understand the LSTM architecture\n",
    "\n",
    "The model consists of:\n",
    "\n",
    "1. **LSTM Layer 1**: Processes the sequence of vital signs, learning temporal patterns. Returns sequences to the next layer.\n",
    "   - 64 units (neurons)\n",
    "   - return_sequences=True: passes output to the next LSTM layer\n",
    "\n",
    "2. **Dropout Layer 1**: Randomly drops 30% of connections during training to prevent overfitting\n",
    "\n",
    "3. **LSTM Layer 2**: Further processes the temporal patterns\n",
    "   - 32 units\n",
    "   - return_sequences=False: only outputs the final time step\n",
    "\n",
    "4. **Dropout Layer 2**: Another dropout layer for regularization\n",
    "\n",
    "5. **Dense Layer**: Fully connected layer that produces the final prediction\n",
    "   - 1 unit with sigmoid activation\n",
    "   - Outputs probability of ICU admission (0 to 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "\n",
    "# First LSTM layer with 64 units\n",
    "# return_sequences=True means it will pass sequences to the next LSTM layer\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(n_timesteps, n_features)))\n",
    "\n",
    "# Dropout layer to prevent overfitting\n",
    "# Randomly sets 30% of inputs to 0 during training\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Second LSTM layer with 32 units\n",
    "# return_sequences=False means it will only output the final time step\n",
    "model.add(LSTM(units=32, return_sequences=False))\n",
    "\n",
    "# Another dropout layer\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Dense output layer with sigmoid activation for binary classification\n",
    "# Outputs a probability between 0 and 1\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "print(\"LSTM model architecture created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model summary\n",
    "# This shows the architecture, number of parameters, and output shapes\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-40",
   "metadata": {},
   "source": [
    "### Compile the model\n",
    "\n",
    "Before training, you need to compile the model by specifying:\n",
    "- **Optimizer**: Adam (adaptive learning rate optimizer)\n",
    "- **Loss function**: Binary crossentropy (for binary classification)\n",
    "- **Metrics**: Accuracy (to monitor during training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),  # Adam optimizer with learning rate 0.001\n",
    "    loss='binary_crossentropy',            # Loss function for binary classification\n",
    "    metrics=['accuracy']                   # Track accuracy during training\n",
    ")\n",
    "\n",
    "print(\"Model compiled and ready for training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-42",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "Now you will train the model on the training data. The model will learn to recognize patterns in vital sign sequences that indicate ICU admission risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# epochs: number of times the model sees the entire training dataset\n",
    "# batch_size: number of samples processed before updating model weights\n",
    "# validation_split: use 20% of training data for validation during training\n",
    "# verbose: 1 shows progress bar, 0 is silent\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nModel training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-44",
   "metadata": {},
   "source": [
    "### Visualize training history\n",
    "\n",
    "Plotting the training and validation accuracy/loss helps you understand how well the model learned and whether it is overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "axes[0].plot(history.history['accuracy'], label='Training Accuracy')\n",
    "axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Model Accuracy Over Time')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot loss\n",
    "axes[1].plot(history.history['loss'], label='Training Loss')\n",
    "axes[1].plot(history.history['val_loss'], label='Validation Loss')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].set_title('Model Loss Over Time')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Training history visualization complete.\")\n",
    "print(\"If training and validation curves are close, the model is generalizing well.\")\n",
    "print(\"If training accuracy is much higher than validation, the model may be overfitting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-46",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate the model and make predictions\n",
    "\n",
    "Now that the model is trained, you will evaluate its performance on the test set (unseen data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "# model.predict returns probabilities\n",
    "y_pred_proba = model.predict(X_test)\n",
    "\n",
    "# Convert probabilities to binary predictions (threshold = 0.5)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "\n",
    "print(f\"Number of predictions: {len(y_pred)}\")\n",
    "print(f\"Predicted ICU admissions: {np.sum(y_pred == 1)}\")\n",
    "print(f\"Predicted no ICU: {np.sum(y_pred == 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-48",
   "metadata": {},
   "source": [
    "### Calculate evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Accuracy Percentage: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display classification report\n",
    "# This shows precision, recall, f1-score for each class\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred, target_names=['No ICU', 'ICU Required']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-51",
   "metadata": {},
   "source": [
    "## Step 7: Display confusion matrix and ROC curve\n",
    "\n",
    "Visual evaluation tools help you understand model performance from a clinical perspective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-52",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "\n",
    "A confusion matrix shows:\n",
    "- True Negatives (TN): Correctly predicted no ICU\n",
    "- False Positives (FP): Incorrectly predicted ICU (false alarm)\n",
    "- False Negatives (FN): Incorrectly predicted no ICU (missed case)\n",
    "- True Positives (TP): Correctly predicted ICU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9259a6-7716-4e0a-92f9-2df588c80b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = sns.heatmap(cm, annot=False, fmt=\"d\", cmap=\"Blues\",\n",
    "                 xticklabels=[\"No ICU\", \"ICU Required\"],\n",
    "                 yticklabels=[\"No ICU\", \"ICU Required\"],\n",
    "                 cbar_kws={\"shrink\": 0.8})\n",
    "\n",
    "# Manually add text annotations with different font sizes\n",
    "labels = [[\"True\\nNegative\", \"False\\nPositive\"],\n",
    "          [\"False\\nNegative\", \"True\\nPositive\"]]\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        # Add the number with larger font\n",
    "        ax.text(j + 0.5, i + 0.4, str(cm[i, j]),\n",
    "               ha=\"center\", va=\"center\",\n",
    "               color=\"orange\", fontsize=24, fontweight='bold')\n",
    "        \n",
    "        # Add the label with smaller font\n",
    "        ax.text(j + 0.5, i + 0.7, labels[i][j],\n",
    "               ha=\"center\", va=\"top\",\n",
    "               color=\"orange\", fontsize=11)\n",
    "\n",
    "plt.title(\"Confusion Matrix\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Predicted\", fontsize=12)\n",
    "plt.ylabel(\"Actual\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nConfusion Matrix Interpretation:\")\n",
    "print(f\"True Negatives (correctly predicted no ICU): {cm[0, 0]}\")\n",
    "print(f\"False Positives (incorrectly predicted ICU): {cm[0, 1]}\")\n",
    "print(f\"False Negatives (missed ICU cases): {cm[1, 0]}\")\n",
    "print(f\"True Positives (correctly predicted ICU): {cm[1, 1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-54",
   "metadata": {},
   "source": [
    "### ROC curve and AUC\n",
    "\n",
    "The Receiver Operating Characteristic (ROC) curve shows the trade-off between sensitivity and specificity at different threshold values.\n",
    "\n",
    "AUC (Area Under Curve) summarizes the ROC curve:\n",
    "- AUC = 1.0: Perfect model\n",
    "- AUC = 0.5: Random guessing\n",
    "- AUC > 0.8: Good model for clinical use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)', fontsize=12)\n",
    "plt.ylabel('True Positive Rate (Sensitivity)', fontsize=12)\n",
    "plt.title('ROC Curve for ICU Admission Prediction', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nROC-AUC Score: {roc_auc:.4f}\")\n",
    "if roc_auc > 0.9:\n",
    "    print(\"Excellent model performance!\")\n",
    "elif roc_auc > 0.8:\n",
    "    print(\"Good model performance for clinical use.\")\n",
    "elif roc_auc > 0.7:\n",
    "    print(\"Acceptable model performance.\")\n",
    "else:\n",
    "    print(\"Model may need improvement for clinical deployment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-56",
   "metadata": {},
   "source": [
    "### Calculate Sensitivity and Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity (Recall) - ability to identify patients who need ICU\n",
    "sensitivity = recall_score(y_test, y_pred, pos_label=1)\n",
    "print(f\"Sensitivity (Recall): {sensitivity:.4f}\")\n",
    "print(f\"Sensitivity Percentage: {sensitivity * 100:.2f}%\")\n",
    "print(\"Sensitivity measures the model's ability to correctly identify patients who require ICU admission.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specificity - ability to identify patients who do not need ICU\n",
    "specificity = recall_score(y_test, y_pred, pos_label=0)\n",
    "print(f\"\\nSpecificity: {specificity:.4f}\")\n",
    "print(f\"Specificity Percentage: {specificity * 100:.2f}%\")\n",
    "print(\"Specificity measures the model's ability to correctly identify patients who do not require ICU admission.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-59",
   "metadata": {},
   "source": [
    "### Clinical interpretation\n",
    "\n",
    "Understanding what these metrics mean in a healthcare context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Clinical Interpretation ===\")\n",
    "print(f\"\\nOut of {np.sum(y_test == 1)} patients who actually required ICU:\")\n",
    "print(f\"  - The model correctly identified: {cm[1, 1]} patients ({sensitivity*100:.1f}%)\")\n",
    "print(f\"  - The model missed: {cm[1, 0]} patients\")\n",
    "\n",
    "print(f\"\\nOut of {np.sum(y_test == 0)} patients who did not require ICU:\")\n",
    "print(f\"  - The model correctly identified: {cm[0, 0]} patients ({specificity*100:.1f}%)\")\n",
    "print(f\"  - The model incorrectly flagged: {cm[0, 1]} patients\")\n",
    "\n",
    "print(\"\\nClinical Decision Making:\")\n",
    "if sensitivity > 0.85:\n",
    "    print(\"High sensitivity: The model catches most patients who need ICU care.\")\n",
    "else:\n",
    "    print(\"Consider adjusting the threshold to improve sensitivity and catch more at-risk patients.\")\n",
    "\n",
    "if specificity > 0.85:\n",
    "    print(\"High specificity: The model avoids unnecessary ICU alerts for stable patients.\")\n",
    "else:\n",
    "    print(\"Some false positives occur, which may lead to unnecessary resource allocation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-61",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "Now, you will practice building an LSTM model on the \"patient_vitals_hospital2.csv\" dataset (https://advanced-machine-learning-for-medical-data-8e1579.gitlab.io/labs/lab9/patient_vitals_hospital2.csv) and use different parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-62",
   "metadata": {},
   "source": [
    "For the exercises, you will create a new synthetic dataset with slightly different characteristics to practice the entire workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-63",
   "metadata": {},
   "source": [
    "### Exercise 1: Loading a different dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-65",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for a hint</summary>\n",
    "    \n",
    "Refer to Step 1, and use \"patient_vitals_hospital2.csv\"\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-66",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "df_ex = pd.read_csv(\"https://advanced-machine-learning-for-medical-data-8e1579.gitlab.io/labs/lab9/patient_vitals_hospital2.csv\")\n",
    "print(f\"Total records: {df.shape[0]}\")\n",
    "print(f\"Number of patients: {df.patient_id.nunique()}\")\n",
    "print(f\"Time steps per patient: {df.shape[0]/df.patient_id.nunique()}\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-67",
   "metadata": {},
   "source": [
    "### Exercise 2: Verify columns and create sequences\n",
    "\n",
    "Verify all columns in the dataset, then create sequences (X) and labels (y). Normalize the sequences using StandardScaler. Display the shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-69",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for a hint</summary>\n",
    "    \n",
    "Refer to Step 3. Use the same feature columns and follow the sequence creation and scaling steps.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-70",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "# Verify columns\n",
    "print(\"Columns in dataset:\")\n",
    "print(df_ex.columns.tolist())\n",
    "\n",
    "# Define features\n",
    "feature_columns_ex = ['heart_rate', 'systolic_bp', 'diastolic_bp', \n",
    "                      'respiratory_rate', 'temperature', 'spo2']\n",
    "\n",
    "# Create sequences\n",
    "patient_ids_ex = df_ex['patient_id'].unique()\n",
    "X_sequences_ex = []\n",
    "y_labels_ex = []\n",
    "\n",
    "for patient_id in patient_ids_ex:\n",
    "    patient_data = df_ex[df_ex['patient_id'] == patient_id].sort_values('time_step')\n",
    "    sequence = patient_data[feature_columns_ex].values\n",
    "    X_sequences_ex.append(sequence)\n",
    "    label = patient_data['icu_admission'].iloc[0]\n",
    "    y_labels_ex.append(label)\n",
    "\n",
    "X_ex = np.array(X_sequences_ex)\n",
    "y_ex = np.array(y_labels_ex)\n",
    "\n",
    "# Normalize\n",
    "n_samples_ex, n_timesteps_ex, n_features_ex = X_ex.shape\n",
    "X_reshaped_ex = X_ex.reshape(-1, n_features_ex)\n",
    "\n",
    "scaler_ex = StandardScaler()\n",
    "X_scaled_ex = scaler_ex.fit_transform(X_reshaped_ex)\n",
    "X_scaled_ex = X_scaled_ex.reshape(n_samples_ex, n_timesteps_ex, n_features_ex)\n",
    "\n",
    "print(f\"\\nX shape: {X_scaled_ex.shape}\")\n",
    "print(f\"y shape: {y_ex.shape}\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-71",
   "metadata": {},
   "source": [
    "### Exercise 3: Split the dataset\n",
    "\n",
    "Split the dataset into training and testing sets (80:20 ratio) with stratification. Display the number of samples in each set and the class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-73",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for a hint</summary>\n",
    "    \n",
    "Refer to Step 4. Use train_test_split with test_size=0.2, random_state=42, and stratify=y_ex\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-74",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "# Split the data\n",
    "X_train_ex, X_test_ex, y_train_ex, y_test_ex = train_test_split(\n",
    "    X_scaled_ex, y_ex, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_ex\n",
    ")\n",
    "\n",
    "print(\"Training set:\")\n",
    "print(f\"  Number of patients: {X_train_ex.shape[0]}\")\n",
    "print(f\"  ICU admissions: {np.sum(y_train_ex == 1)}\")\n",
    "print(f\"  No ICU admissions: {np.sum(y_train_ex == 0)}\")\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "print(f\"  Number of patients: {X_test_ex.shape[0]}\")\n",
    "print(f\"  ICU admissions: {np.sum(y_test_ex == 1)}\")\n",
    "print(f\"  No ICU admissions: {np.sum(y_test_ex == 0)}\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-75",
   "metadata": {},
   "source": [
    "### Exercise 4: Build and train LSTM model\n",
    "\n",
    "Build an LSTM model with the following architecture:\n",
    "- First LSTM layer: 128 units, return_sequences=True\n",
    "- Dropout: 0.4\n",
    "- Second LSTM layer: 64 units, return_sequences=False\n",
    "- Dropout: 0.4\n",
    "- Dense output layer: 1 unit, sigmoid activation\n",
    "\n",
    "Compile with Adam optimizer (learning_rate=0.001) and train for 40 epochs with batch_size=16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-77",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for a hint</summary>\n",
    "    \n",
    "Refer to Step 5. Use Sequential model and add layers in order. Remember to use input_shape for the first layer.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-78",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "# Build model\n",
    "model_ex = Sequential()\n",
    "model_ex.add(LSTM(units=128, return_sequences=True, \n",
    "                  input_shape=(n_timesteps_ex, n_features_ex)))\n",
    "model_ex.add(Dropout(0.4))\n",
    "model_ex.add(LSTM(units=64, return_sequences=False))\n",
    "model_ex.add(Dropout(0.4))\n",
    "model_ex.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile\n",
    "model_ex.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Model architecture:\")\n",
    "model_ex.summary()\n",
    "\n",
    "# Train\n",
    "history_ex = model_ex.fit(\n",
    "    X_train_ex, y_train_ex,\n",
    "    epochs=40,\n",
    "    batch_size=16,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-79",
   "metadata": {},
   "source": [
    "### Exercise 5: Make predictions\n",
    "\n",
    "Use the trained model to make predictions on the test set. Convert probabilities to binary predictions using a threshold of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-81",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for a hint</summary>\n",
    "    \n",
    "Use model.predict() to get probabilities, then apply threshold > 0.5 to convert to binary predictions.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-82",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "# Make predictions\n",
    "y_pred_proba_ex = model_ex.predict(X_test_ex)\n",
    "y_pred_ex = (y_pred_proba_ex > 0.5).astype(int).flatten()\n",
    "\n",
    "print(f\"Number of predictions: {len(y_pred_ex)}\")\n",
    "print(f\"Predicted ICU admissions: {np.sum(y_pred_ex == 1)}\")\n",
    "print(f\"Predicted no ICU: {np.sum(y_pred_ex == 0)}\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-83",
   "metadata": {},
   "source": [
    "### Exercise 6: Calculate Accuracy and display classification report\n",
    "\n",
    "Calculate the model accuracy and display the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-85",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for a hint</summary>\n",
    "    \n",
    "Use accuracy_score() and classification_report() from sklearn.metrics\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-86",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "# Calculate accuracy\n",
    "accuracy_ex = accuracy_score(y_test_ex, y_pred_ex)\n",
    "print(f\"Model Accuracy: {accuracy_ex:.4f}\")\n",
    "print(f\"Accuracy Percentage: {accuracy_ex * 100:.2f}%\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(classification_report(y_test_ex, y_pred_ex, \n",
    "                          target_names=['No ICU', 'ICU Required']))\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-87",
   "metadata": {},
   "source": [
    "### Exercise 7: Print Sensitivity and Specificity\n",
    "\n",
    "Calculate and display sensitivity and specificity as percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-89",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for a hint</summary>\n",
    "    \n",
    "Use recall_score() with pos_label=1 for sensitivity and pos_label=0 for specificity\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-90",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "# Sensitivity (Recall for ICU class)\n",
    "sensitivity_ex = recall_score(y_test_ex, y_pred_ex, pos_label=1)\n",
    "print(f\"Sensitivity (Recall): {sensitivity_ex:.4f}\")\n",
    "print(f\"Sensitivity Percentage: {sensitivity_ex * 100:.2f}%\")\n",
    "print(\"This measures the ability to identify patients who require ICU admission.\")\n",
    "\n",
    "# Specificity (Recall for No ICU class)\n",
    "specificity_ex = recall_score(y_test_ex, y_pred_ex, pos_label=0)\n",
    "print(f\"\\nSpecificity: {specificity_ex:.4f}\")\n",
    "print(f\"Specificity Percentage: {specificity_ex * 100:.2f}%\")\n",
    "print(\"This measures the ability to identify patients who do not require ICU admission.\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-91",
   "metadata": {},
   "source": [
    "# Congratulations! \n",
    "You have completed this lab on predicting clinical deterioration using LSTM networks. You now know how to prepare time-series healthcare data, train an LSTM model, and evaluate its performance using key metrics and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-92",
   "metadata": {},
   "source": [
    "## Authors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-93",
   "metadata": {},
   "source": [
    "Ramesh Sannareddy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-94",
   "metadata": {},
   "source": [
    "Copyright © 2025 SkillUp. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
