{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95bd70d0",
   "metadata": {},
   "source": [
    "\n",
    "# Generative AI–based Medical Chatbot Application\n",
    "\n",
    "This template provides a starting point to help you complete the project efficiently. You can use it as-is, modify it, or create your own structure; just be sure to complete all the required tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68f5be0",
   "metadata": {},
   "source": [
    "\n",
    "## Project overview\n",
    "\n",
    "In this project, you will apply your skills to build a simple **Gradio-based medical chatbot** that can:\n",
    "- Take a clinical report as input\n",
    "- Accept a user’s question\n",
    "- Generate a concise, relevant answer using a **pre-trained Seq2Seq model** such as `google/flan-t5-small` or `facebook/bart-base`.\n",
    "\n",
    "You will complete each task step by step and add screenshots of your outputs for submission.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ba0452",
   "metadata": {},
   "source": [
    "\n",
    "## Task 1: Develop the Gradio web application interface\n",
    "\n",
    "**Goal:** Create a basic Gradio interface for the chatbot.\n",
    "\n",
    "**Instructions:**\n",
    "- Add text boxes for:\n",
    "  - Medical report input\n",
    "  - Question input\n",
    "  - Answer output\n",
    "- Add a “Get the Answer” button.\n",
    "- Test to ensure the layout displays correctly.\n",
    "\n",
    "Write your code in the cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394b9670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the Gradio interface layout here\n",
    "# Hint: Use gr.Textbox() for inputs and outputs, and gr.Button() for the button.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33260184",
   "metadata": {},
   "source": [
    "\n",
    "## Task 2: Integrate a lightweight LLM\n",
    "\n",
    "**Goal:** Load and prepare a pre-trained lightweight Seq2Seq model from Hugging Face.\n",
    "\n",
    "**Instructions:**\n",
    "- Select a model such as `google/flan-t5-small` or `facebook/bart-base`.\n",
    "- Load the model and tokenizer using `AutoTokenizer` and `AutoModelForSeq2SeqLM`.\n",
    "- Create a `pipeline` with `\"text2text-generation\"` type.\n",
    "- Run a small test prompt to confirm it generates a response.\n",
    "\n",
    "Write your code in the cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c179a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load your Seq2Seq model and tokenizer here\n",
    "# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "# model_name = \"google/flan-t5-small\"\n",
    "# tokenizer = ...\n",
    "# model = ...\n",
    "# nlp_pipeline = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc3cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test your model with a short prompt (e.g., a small clinical report and question)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fc714a",
   "metadata": {},
   "source": [
    "\n",
    "## Task 3: Implement the Answering Function\n",
    "\n",
    "**Goal:** Implement a Python function that uses your model to answer clinical questions.\n",
    "\n",
    "**Instructions:**\n",
    "- Define a function `generate_answer(report, question)`.\n",
    "- Validate inputs (return a friendly message if missing).\n",
    "- Build the prompt using the format: `question: <question> context: <report>`.\n",
    "- Use your pipeline to generate the answer.\n",
    "- Return the model’s generated text.\n",
    "\n",
    "Write your function below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb702e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your generate_answer(report, question) function here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743a0687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test your function with a sample report and question\n",
    "# Example:\n",
    "# report = \"The patient presents with persistent cough and fever. Chest X-ray shows signs of pneumonia.\"\n",
    "# question = \"What is the diagnosis?\"\n",
    "# print(generate_answer(report, question))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17306b3e",
   "metadata": {},
   "source": [
    "\n",
    "## Task 4: Test the application\n",
    "\n",
    "**Goal:** Integrate your answering function with the Gradio interface and test the chatbot end-to-end.\n",
    "\n",
    "**Instructions:**\n",
    "- Connect your `generate_answer` function to the Gradio interface button.\n",
    "- Launch the app and test with a sample medical report and question.\n",
    "- Verify that the generated answer appears correctly.\n",
    "\n",
    "Write your integration code below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8232e637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Integrate your answering function with the Gradio interface and launch it\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
